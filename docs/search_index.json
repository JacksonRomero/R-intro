[
["index.html", "Introducción a estadística con R Prefacio", " Introducción a estadística con R Matias Andina 2018-08-08 Prefacio R es quizás el lenguaje más desarrollado para realizar análisis exploratorios de datos y estadística. Debido a que posee una naturaleza dinámica, gratuita, open-source, y una comunidad que trabaja activamente en incrementar las posibilidades del lenguage, es un candidato natural para ser utilizado tanto en academia como en ámbitos profesionales. Creo que no exajero al decir que aprender R cambió mi vida, me abrió los ojos a un mundo de posibilidades que continúo explorando. Escribo porque tengo deseo de devolver lo que la comunidad de R me ha regalado. Escribo en español porque es mi idioma nativo y porque siento que puedo contribuir a reducir la barrera del lenguaje inglés, que complica el aprendizaje de cualquier lenguaje de programación. Escribiendo este libro me di cuenta de que no es trivial encontrar material de referencia en relación a R (o estadística) enteramente en español. Mi objetivo principal es abrir la puerta, facilitar que hispanohablantes aprendan conceptos fundamentales de estadística y R. La curva de aprendizaje es empinada, aconsejo abrocharse el cinturón de seguridad y abrazar el camino. Este libro es un experimento e invita a la experimentación. Adelante. Este libro está en construcción y planeo continuar actualizándolo con el tiempo. "],
["introduccion.html", "Capítulo 1 Introducción 1.1 Términos 1.2 Dónde encontrar ayuda 1.3 Sistema Operativo 1.4 Directorios 1.5 Traducción de contenido 1.6 R 1.7 Instalar R 1.8 Instalar Rstudio 1.9 Resumen Anexo", " Capítulo 1 Introducción La organización de este libro esta fuertemente vinculada al análisis de datos. En general, el análisis suele presentarse en tres etapas: Lectura, modelado y comunicación de resultados. Lectura &gt; Modelado &gt; Comunicación En lo que resta de este capítulo, vamos a transitar parte de la organización y contenido del libro, las convenciones que vamos a utilizar y los requisitos para obtener los programas necesarios. El contenido a desarrollar es de nivel básico. Sugiero que los usuarios que ya hayan instalado R o se sientan cómodos con la instalación de programas y sistema de archivos se salteen lo siguiente. 1.1 Términos Existen ciertos términos en inglés que no poseen una traducción satisfactoria al español y serán utilizados inglés. La decisión es arbitraria, aunque intento mantenerme dentro de anglicismos aceptados, recomiendo tratarlos como términos técnicos. En el anexo de este capítulo pueden encontrar una tabla con los términos técnicos. Un caso especial son los nombres nativos de objetos o propiedades de R. Estos términos aparecerán normalmente resaltados en el texto. Un ejemplo son las tablas que vamos a usar para acceder a datos, llamadas data.frame. Por ahora, no es necesario preocuparse al respecto, las piezas del rompecabezas se van a unir luego. 1.2 Dónde encontrar ayuda Una gran forma de resolver los problemas que tenemos cuando escribimos código es goolgear el problema exacto. R normalmente nos mostrará errores de la forma: ## Error: error message here Copiar y pegar el error particular es de gran ayuda. Existen diversos foros especializados. Afortunadamente existe material en español (aunque es limitado). Un gran sitio para empezar es: StackOverflow en español! https://es.stackoverflow.com/ 1.3 Sistema Operativo Afortunadamente, vivimos en un mundo con diversidad de sistemas operativos. R es compatible con Windows, Mac OS y Linux. Este libro está escrito utilizando Windows 10 por lo que es posible que algunos ejemplos funcionen distinto en otros sistemas operativos. Haré mis mayores esfuerzos para asegurar compatibilidad entre distintos sistemas. 1.4 Directorios Los directorios son direcciones en nuestra computadora. Para que nuestra computadora localice un archivo o un programa, estos tienen una dirección en el disco duro. Normalmente el sistema de archivos es jerárquico, con secuencias de contenedores. Por ende, los directorios son también conocidos como carpetas o ficheros. Por ejemplo, en mi sistema, los archivos de R se encuentra en este directorio C:\\Program Files\\R\\R-3.4.0. Todos los archivos contenidos en esa carpeta serán localizados a partir de esa dirección (y el nombre del archivo). Es importante entender que siempre contaremos con un working directory o directorio en el que estamos trabajando. Este directorio funciona como todos los demás, funcionando como un atajo. 1.5 Traducción de contenido Una parte del material de referencia en este libro está en inglés. Para aquellos lectores que encuentren muy dificultoso el idioma, aconsejo intentar la traducción del material usando el traductor de Google o, si el navegador lo permite, habilitar la traducción de manera directa sobre el contenido. 1.6 R Un lenguaje de programación es una serie de reglas que están diseñadas para realizar procesos en una computadora.1 R es un lenguaje de programación. En ese sentido, no se diferencia de ningún otro (ej. C, Python). A su vez, como todo lenguaje, el set de reglas es particular y lleva tiempo incorporarlo. La mejor forma de naturalizarse con un idioma es hablarlo y, fundamentalmente en este caso, leerlo y escribirlo! Afortunadamente, el dominio de un idioma facilita el dominio de otro(s). R nació en 1993 en Auckland. Sin embargo, su origen puede rastrearse hasta un lenguaje previo llamado S, creado por John Chambers y colaboradores en Bell Laboratories durante la década de 1970.2 Actualmente, la diversidad de proyectos que pueden abarcarse en R es altísima, desde hacer análisis de estadística pura hasta escribir libros, como éste. En este libro voy a usar mayoritariamente R para hablar del lenguaje. Una excepción es la instalación del programa en sí mismo (ver Instalar R). El copyright del software R es mantenido por la fundación R ( R Foundation ) bajo una licencia pública GNU General Public License version 2.0. Algunas traducciones no oficiales de la licencia pueden encontrarse aquí. La fundación R es una organización sin fines de lucro que trabaja en pos del interés público. Fue fundada por los miembros del R Development Core Team para proveer. Sus objetivos son: Proveer apoyo al proyecto R y otras innovaciones en estadística computacional. Asegurar su continuo desarollo, así como también el desarrollo de futuras innovaciones en software estadístico. Proveer un punto de referencia para individuos, instituciones y empresas que deseen interactuar con la comunidad de desarrollo de R. Mantener y administrar el copyright del software R y su documentación.3 Podemos pensar a R estando dividido en dos marcos conceptuales: El sistema de “base” R descargado desde CRAN. El conjunto de paquetes externos que agregan funcionalidad. En la siguientes secciones realizaremos la descarga e instalación de R. En el próximo capítulo trabajaremos con agregar funcionalidad utilizando paquetes externos. 1.7 Instalar R Para instalar R debemos dirigirnos a la colección de paquetes en CRAN (del inglés, Comprehensive R Archive Network). CRAN es un repositorio global donde se puede acceder al software y a los paquetes que la comunidad produce. Veremos pronto que R provee limitada funcionalidad de base y los paquetes son una parte fundamental del uso diario. La instalación comienza entrando en https://cran.r-project.org/ Seleccionar el link correcto de descarga. El link depende del sistema operativo. Links para descargar R en CRAN Hacer clic en Install R for the first time (instalar R por primera vez). Instalar por primera vez Hacer clic en Download R 3.4.3 for Windows para descargar el ejecutable. Al momento de escribir este libro la versión 3.4.3 es la última disponible en CRAN. Descargar Instalar desde el .exe (El cuádro de dialogo permite seleccionar idioma español). 1.7.1 Terminal de R Si fantaseamos con escribir desde un terminal, es posible ejecutar R de ese modo. En mi caso, el acceso al terminal se encuentra en C:\\Program Files\\R\\R-3.4.0\\bin y la aplicación es Rterm. Como pueden ver, estoy utilizando una versión desactualizada, R version 3.4.0 (2017-04-21) -- &quot;You Stupid Darkness&quot;. Terminal de R en mi sistema 1.7.2 Interfaz gráfica Si bien el terminal (o consola) es seductor, en muchas ocasiones es conveniente tener una interfaz gráfica. Podemos acceder a la interfaz RGui desde C:\\Program Files\\R\\R-3.4.0\\bin\\i386 o directamente si hemos creado un acceso directo en el escritorio durante nuestra instalación. La interfaz gráfica se ve de este modo: Interfaz Gráfica de R Como podemos ver, la interfaz permite acceso a mayores opciones pero, en esencia, se asemeja al terminal. Afortunadamente, existe una versión ampliamente mejorada de esta experiencia, se llama Rstudio (ver Instalar Rstudio). Rstudio es la interfaz gráfica que utilizaremos en este libro. 1.8 Instalar Rstudio Rstudio es un software que integra una serie de herramientas gráficas y variabilidad de opciones a R. De este modo, ganamos versatilidad y comodidad en el uso. En el día a día, abrir Rstudio es, a fines prácticos, abrir R. Para instalar Rstudio, podemos seguir los siguientes pasos: Ir a https://www.rstudio.com/products/rstudio/download/ Hacer clic en Descargar software. Seleccionar la version compatible con el sistema operativo. Instalar desde el .exe descargado. Descargar Rstudio 1.8.1 La experiencia Al abrir Rstudio nos encontraremos con un programa que tiene principalmente dos áreas, una de entrada (consola) y una de salida (exploradores): Rstudio al abrir Podemos hacer un intento rápido para graficar el histograma de una distribución Normal con media 0 y desvío estándar 1. Puedes copiar y pegar el siguiente código en la consola. set.seed(123) ejemplo &lt;- rnorm(n = 10000, mean = 0, sd = 1) hist(ejemplo, col=&#39;orange&#39;, breaks=40, ylab = &quot;Frecuencia&quot;, main = &quot;Histograma ejemplo&quot;) En la ventana de Rstudio se vería así: Así se ve en Rstudio Normalmente usaremos Rstudio con 4 zonas principales: Editor de scripts. Terminal o consola. Explorador de entorno e historial. Explorador de archivos y gráficos. Rstudio al iniciar un script En los próximos capítulos ahondaremos en la funcionalidad de cada uno. 1.8.2 Preferencias Rstudio permite personalizar la experiencia R de modo de obtener virtualmente infinitas combinaciones. Para mayor información visitar la página de Rstudio 1.9 Resumen La organización del análisis estadístico procede Lectura &gt; Modelado &gt; Comunicación R es un lenguaje de programación orientado a objetos que permite realizar las tres etapas. El software R es de dedistribución gratuita y con funcionalidad dividida en: Base R. Paquetes externos descargados de un repositorio. Rstudio es una interfaz gráfica gratuita que permite trabajar con R. Anexo La suguiente tabla muestra ciertos terminos que serán utilizados en inglés. Término en inglés Descripción CRAN Colección de paquetes en CRAN (Comprehensive R Archive Network) dataset set de datos render generación de contenido multimedia software programa subset subconjunto o porción working directory Directorio desde donde R está trabajando en la sesión (getwd()) Mayor descripción en lenguajes de programación aquí.↩ Historia e información sobre R [aquí](https://es.wikipedia.org/wiki/R_(lenguaje_de_programaci%C3%B3n). Para aquellos curiosos que tienen una consola a mano y se aventuran al inglés: contributors()↩ La traducción es de mi autoría, la información original en inglés puede encontrarse aquí.↩ "],
["primeros-pasos.html", "Capítulo 2 Primeros Pasos 2.1 Ejecutar código 2.2 Crear Objetos 2.3 Clases de objetos en R 2.4 Errores comunes 2.5 Instalar y cargar paquetes 2.6 Recursos", " Capítulo 2 Primeros Pasos Como se mencionó en el capítulo anterior, R contiene funcionalidad limitada de base. Por eso, una vez instalados los requisitos mínimos, debemos comenzar a instalar aquellos paquetes útiles. Los paquetes son grupos de funciones útiles, que pueden usarse de forma repetida y reproducible entre usuarios. En particular, recomiendo fuertemente instalar tidyverse, un compendio de paquetes para hacer manejo y visualización de datos.4 2.1 Ejecutar código Ejecutar (o correr) código en R puede realizarse desde la consola o desde el editor de scrips. En el editor, podemos seleccionar las líneas de código y presionar Ctr+Enter para que las líneas seleccionadas se ejecuten. 2.2 Crear Objetos R es un lenguaje orientado a objetos. Los objetos pueden ser usados para guardar valores y pueden modificarse (mediante funciones) como por ejemplo sumar dos objetos o calcular la media. 2.2.1 El operador &lt;- Para crear objetos asignamos (con el operador &lt;-) valores a una variable. Por ejemplo, creemos un vector x que vaya de 1 a 10. # Crear un vector en secuencia de 1 a 10 x &lt;- 1:10 # Ver el vector x ## [1] 1 2 3 4 5 6 7 8 9 10 En general, podemos pensarlo de este modo: nombre_del_objeto &lt;- valor_del_objeto5 Las operaciones algebráicas con R siguen reglas matemáticas y son aplicadas a los elementos del vector. # Sumar x + 1 ## [1] 2 3 4 5 6 7 8 9 10 11 # Multiplicar x * 2 ## [1] 2 4 6 8 10 12 14 16 18 20 # Operaciones combinadas (x^2 + 1) / 1.5 ## [1] 1.333333 3.333333 6.666667 11.333333 17.333333 24.666667 33.333333 ## [8] 43.333333 54.666667 67.333333 2.3 Clases de objetos en R Hasta ahora, nuestro objeto x es un simple vector de 1 dimensión y es de tipo entero o integer (puedes verificarlo con class(x) en la consola). La riqueza de R radica en la posibilidad de trabajar con distintas clases de objetos. R tiene cinco clases básicas de vectores: character (letras) numeric (números reales) integer (números enteros) complex (números complejos) logical (verdadero/falso o True/False) Lo más importante es que los vectores sólo pueden contener elementos de la misma clase. Por ejemplo, no es posible tener un vector de la siguiente forma: c(1, &quot;perro&quot;, FALSE, &quot;gato&quot;, 1.5) pero sí es posible tenerlo de esta forma: c(&quot;1&quot;, &quot;perro&quot;, &quot;FALSE&quot;, &quot;gato&quot;, &quot;1.5&quot;). En este caso, aunque bastante inconveniente, todos los elementos son de tipo character. R automaticamente fuerza el resultado para no obtener errores (en un proceso llamado coerción). En nuestro ejemplo: # Crear un vector con problemas de clases prueba &lt;- c(1, &quot;perro&quot;, FALSE, &quot;gato&quot;, 1.5) # Ver el vector prueba ## [1] &quot;1&quot; &quot;perro&quot; &quot;FALSE&quot; &quot;gato&quot; &quot;1.5&quot; # Clase del vector class(prueba) ## [1] &quot;character&quot; Un problema de la coerción de datos es que no es posible para todos los casos. Allí, R agrega NA. Por ejemplo: # Transformar nuestro vector a numérico as.numeric(prueba) ## Warning: NAs introduced by coercion ## [1] 1.0 NA NA NA 1.5 Los NAs (del inglés not available) son datos faltantes. Nuestros datos reales pueden contener NA y normalmente es muy útil tenerlos en cuenta. Para chequear si un vector contiene NA podemos usar la funcion is.na(), por ejemplo: # Nuestro vector previo prueba_num &lt;- as.numeric(prueba) ## Warning: NAs introduced by coercion # Chequeamos si tiene NA is.na(prueba_num) ## [1] FALSE TRUE TRUE TRUE FALSE Podemos tener NA de tipo character, cuando un vector de tipo character tiene espacios vacíos. Por ejemplo, # Nuestro vector previo vector_palabra &lt;- c(&quot;Lo esencial es&quot;, NA, &quot;a los ojos&quot;) # Chequeamos si tiene NA is.na(vector_palabra) ## [1] FALSE TRUE FALSE Además, podemos contar con vectores que contienen palabras y guardan un orden de niveles como los factores (factor). Por ejemplo: # Creemos un factor con niveles grupo_altura &lt;- factor(c(&quot;mediano&quot;, &quot;pequeño&quot;, &quot;grande&quot;, &quot;muy grande&quot;), levels=c(&quot;pequeño&quot;, &quot;mediano&quot;, &quot;grande&quot;, &quot;muy grande&quot;)) # Veamos el factor grupo_altura ## [1] mediano pequeño grande muy grande ## Levels: pequeño mediano grande muy grande Una situación en la que nos importa el orden es al graficar los datos. Si no tenemos el grupo como character (o como factor con orden incorrecto), obtendremos un gráfico cuyo eje x está ordenado alfabéticamente en vez de tener el orden correcto. Finalmente, vectores vacíos (NULL) nos permiten hacer ciertas operaciones más complejas (ver más adelante). Otras clases de objetos incluyen listas (list), matrices (matrix), tablas de datos (data.frame) y modelos (por ejemplo lm para modelos lineales). Las distintas clases de objetos irán apareciendo a lo largo del texto. 2.4 Errores comunes La curva de aprendizaje de R es inclinada. La barrera del lenguaje es real. Por ejemplo, supongamos que queremos ordenar nuestro vector x de modo descendente (de 10 a 1). Para ello sería muy conveniente saber que sort es la forma de decir ordenar en inglés. Luego, los programadores probablemente incluyeron una función sort().6 # Usamos decreasing=T para marcar orden descendente sort(x, decreasing=T) ## [1] 10 9 8 7 6 5 4 3 2 1 Además de la barrera del lenguaje, es muy común realizar errores de tipeo. La realidad es que no podemos enojarnos con la máquina cuando ocurren, su trabajo es ser exacta, no leernos la mente :). Veamos un ejemplo: # Tengamos la palabra &#39;perro&#39; en un objeto palabra &lt;- &quot;perro&quot; # Hagamos una lista de palabras palabras &lt;- c(&#39;hola&#39;, &#39;como&#39;,&#39;estas&#39;,&#39;?&#39;) Un error común será pedir palabra cuando queremos palabras y vice versa. Además, tendremos problemas de longitud (1 vs 4) que pueden romper el código o provocar errores inesperados. Estos problemas surgen cuando usamos dIsTinTaS FoRmAs De EsCrIbIR. R es sensible a cambios de mayúsculas, por ejemplo: # Pidamos palabra de nuevo Palabra ## Error in eval(expr, envir, enclos): object &#39;Palabra&#39; not found El error indica que no tenemos Palabra en el entorno, lo cual es cierto! Cuando manejamos muchos objetos, estos errores tienden a pasar desapercibidos y provocar dolores de cabeza. Estos errores son muy comunes cuando nombramos mal los objetos o hacemos abuso de copiar y pegar. Por ejemplo: variable1 &lt;- 1:10 variable2 &lt;- variable1 + 5 variable3 &lt;- variable1 + 5 # Error! era variable2 pero no me di cuenta # La confusión se propaga de manera silenciosa!!!! variable4 &lt;- variable1 * variable2 * variable3 Nombrar objetos es difícil! Aunque conlleve nombres más largos, recomiendo nombrar los objetos de la forma más descriptiva posible7. Recuerden que su futuro ser (aquél que quiera usar el código unos meses después de haberlo escrito) no tendrá la menor idea de cómo llamó a las variables.Por ejemplo, # Mala práctica # Nombrando con única letra A &lt;- 5 B &lt;- 9.8 C &lt;- A * B # Mejor # (sin acentos) masa &lt;- 5 aceleracion &lt;- 9.8 fuerza &lt;- masa * aceleracion Un caso muy particular es el de los caracteres protegidos por R. Por ejemplo, c (operación para concatenar objetos), t (operación para transponer), T (atajo para el concepto lógico verdadero o TRUE) o pi (constante \\(\\pi\\)), entre otros. Utilizar estos valores crea inconvenientes con las funciones nativas del sistema (le creamos a R el conflicto entre tranponer un objeto o utilizar el objeto t). Una ventaja de tener idioma nativo distinto de inglés es que nos permite llamar a los objetos en castellano sin crear conflicto con las funciones del sistema (por ejemplo, podemos crear el objeto VERDADERO sin remordimientos). Parte de realizar progresos con el lenguage (y con nuestro deseado análisis de datos) es lograr dialogar en los términos que R entiende. Es completamente normal sentirse frustrado con R. Adelante! 2.5 Instalar y cargar paquetes Para instalar paquetes desde CRAN podemos correr: install.packages(&quot;tidyverse&quot;) En este caso, la última versión de tidyverse (la última versión de los paquetes que lo conforman) será incorporadas a nuestra librería de paquetes. Instalar paquetes debe hacerse únicamente la primera vez. A partir de ahí, debemos indicarle a R que deseamos que esas funciones estén disponibles al iniciar el programa. La función library() es la que utilizamos para cargar paquetes, por ejemplo: library(tidyverse) Para cargar múltiples paquetes a la misma vez, es posible realizar una lista de paquetes y llamar a library() de manera recursiva. muchos_paquetes &lt;- c(&#39;ggplot2&#39;, &#39;dplyr&#39;, &#39;tidyr&#39;, &#39;maptools&#39;) lapply(muchos_paquetes, function(x) require(x, character.only = T)) Volveremos sobre este ejemplo en el futuro cuando veamos la utilidad de las funciones de tipo apply. 2.6 Recursos Un buen manual en español aquí La página oficial de tidyverse y los paquetes que contiene está en ingles aquí↩ Notar los espacios antes y despues del operador &lt;-. Esto es intencional y es aconsejable como buenas prácticas a la hora de escribir. Cuando tenemos muchas líneas de código es más agradable a la vista y facilita la lectura.↩ Si bien la barrera es real, no debemos entrar en pánico. Siempre intenten en Google (búsqueda o traductor) para entender las funciones.↩ Muchas veces yo caigo en la tentación y nombro gráficos con una sola letra (o letra y numero) p1, p2, ....↩ "],
["leer-datos.html", "Capítulo 3 Leer Datos 3.1 Datasets de base 3.2 Importar datos de manera manual 3.3 Archivos de texto 3.4 Otros formatos", " Capítulo 3 Leer Datos En este capítulo vamos a focalizarnos en las diversas formas de entrar datos a R. 3.1 Datasets de base R contiene datasets que pueden ser utilizados directamente. Para dar un vistazo a los paquetes paquetes &lt;- library(help = &quot;datasets&quot;) head(paquetes$info[[2]]) ## [1] &quot;AirPassengers Monthly Airline Passenger Numbers 1949-1960&quot; ## [2] &quot;BJsales Sales Data with Leading Indicator&quot; ## [3] &quot;BOD Biochemical Oxygen Demand&quot; ## [4] &quot;CO2 Carbon Dioxide Uptake in Grass Plants&quot; ## [5] &quot;ChickWeight Weight versus age of chicks on different diets&quot; ## [6] &quot;DNase Elisa assay of DNase&quot; Para ver la lista completa con toda la información, entrar paquetes en la consola nos abrirá una ventana. Utilizar datos que vienen con la instalación R nos facilitará avanzar hacia modelado y comunicación. Por ejemplo, en muchas ocasiones utilizaremos el dataset iris, que contiene información sobre la longitud de pétalos y sépalos en tres plantas distintas. Si bien importar datos es crucial, recomiendo que los usuarios menos experimentados continuen con el siguiente capítulo. A continuación se darán detalles más específicos para importar datos a R. 3.2 Importar datos de manera manual Rstudio posee una pestaña en donde tenemos el Entorno y un botón que nos permite importar datasets (ver figura). Desaconsejo utilizar esta pestaña de manera recurrente debido a que es de poca utilidad para leer archivos grandes. Además, aprender a importar archivos usando código nos permite leer múltiples archivos con gran velocidad, tarea prácticamente imposible si utilizamos los cuadros de diálogo. Importar manualmente Luego recibiremos la posibilidad de seleccionar el archivo y modificar parámetros en sendos cuadros de diálogo. 3.3 Archivos de texto La gran ventaja de mantener archivos de texto (por ejemplo, .csv o .txt) es que una enorme cantidad de software es capaz de leerlos y no están ligados a un sistema operativo. Estos archivos son normalmente livianos y es fácil mantenerlos como sólo lectura, es decir, archivos en los que no cambiamos la información, sólo accedemos a ella. Si nuestros datos están guardados en un archivo de texto de sólo lectura, es menos probable que ocurra corrupción de datos o que, con el paso del tiempo, los mismos no puedan abrirse porque el software se ha discontinuado. R tiene funciones genéricas para abrir este tipo de archivos en una tabla como read.table(...). Esta función presume pocas cosas en la estructura de datos, por lo que permite especificar un montón de parámetros y nos brinda variabilidad (ver help(read.table)). Sin embargo, en general conocemos la estructura de nuestros datos (por ejemplo, la primera fila es el título de las columnas o es un archivo separado por comas). Por lo tanto, usaremos llamadas del estilo: datos &lt;- read.csv(file = &#39;nombre_de_archivo.csv&#39;) Es común que las computadoras en español utilicen el separador ; en vez de , para archivos .csv. En ese caso, podemos especificar: datos &lt;- read.csv(file = &#39;nombre_de_archivo.csv&#39;, sep = &#39;;&#39;) Un archivo separado por tabulaciones (.txt) puede leerse como: datos &lt;- read.table(file = &#39;nombre_de_archivo.txt&#39;, sep = &#39;\\t&#39;) 3.3.1 Importar múltiples archivos de texto Normalmente tendremos múltiples archivos de texto, probablemente llamados de manera seriada en una carpeta dentro de nuestro working directory (por ejemplo, tendremos resultados/sujeto001.csv, resultados/sujeto002.csv, … resultados/sujeto154.csv). # Obtener lista de archivos dentro de la carpeta &#39;resultados&#39; lista_nombres &lt;- list.files(path = &#39;resultados&#39;) # leer todos los archivos en una nueva lista lista_archivos &lt;- lapply(lista_nombres, read.csv()) Esta estrategia nos ahorra tener que escribir 154 llamadas a read.csv() con el nombre de archivo correcto. También facilita el acceso a todas las tablas en un único objeto, la lista lista_archivos. 3.4 Otros formatos 3.4.1 Desde la web Es posible utilizar una URL para leer datos. Es necesario conocer la dirección directa al archivo de texto y su extensión. datos &lt;- read.table(&quot;http://www.algunapagina.com/datos/nombre-archivo.txt&quot;) 3.4.2 SAS Si jugaron con los cuadros de diálogo para importar datos de forma manual, probablemente se toparon con el paquete haven, por ejemplo podemos leer desde SAS usando: library(haven) dataset &lt;- read_sas(...) También es posible usar foreign y la función read.ssd(). 3.4.3 SPSS R puede leer datos directamente de spss: El paquete foreign contiene la función read.spss(). El paquete haven y la función read_spss(). 3.4.4 Excel En algún momento tendremos que leer datos en la forma .xls o .xlsx. Existen distintos paquetes que permiten realizar la tarea, por ejemplo: readxl contiene la función read_excel(), entre otras. xlsx contiene la función read.xlsx(), entre otras. "],
["exploracion-de-datos.html", "Capítulo 4 Exploración de Datos 4.1 Gráficos de base 4.2 ggplot2 4.3 Caso de estudio 4.4 Resumen 4.5 Recursos 4.6 Respuestas", " Capítulo 4 Exploración de Datos Los humanos somos animales fuertemente dependientes en nuestra visión, así hemos evolucionado. Por lo tanto, no es sorpendente que la herramienta más útil para comprender datos sea utilizar una gráfica. 4.1 Gráficos de base R posee funcionalidad gráfica de base. Con relativa facilidad podemos hacer una gráfica de dos variables (por ejemplo, una hipotética variable respuesta en el tiempo). tiempo &lt;- c(1:10) respuesta &lt;- c(1:4, seq(10, 20, 2)) plot(tiempo,respuesta, type=&#39;b&#39;, pch=19, col=&quot;black&quot;, main = &quot;Respuesta vs tiempo&quot;, ylab = &quot;Respuesta&quot;, xlab = &quot;Tiempo&quot;) Esta funcionalidad no está limitada a gráficos de puntos y líneas. Por ejemplo, el histograma que figura en el principio del libro fue realizado con la función hist() set.seed(123) ejemplo &lt;- rnorm(n = 10000, mean = 0, sd = 1) hist(ejemplo, col=&#39;orange&#39;, breaks=40, ylab = &quot;Frecuencia&quot;, main = &quot;Histograma ejemplo&quot;) Los gráficos de base son geniales para explorar modelos ya que aceptan objetos de tipo lm (ver siguientes capítulos). Si bien es posible realizar gráficos muy bonitos con la funcionalidad de base, incluso gráficas de calidad para publicación impresa, es cierto que la gramática no es sencilla de recordar (o requiere demasiada previsión) y, en muchos casos, es limitada. 4.2 ggplot2 Una forma más intuitiva de construir gráficas es utilizar capas. El paquete ggplot2 pertenece al tidyverse y es el más utilizado para realizar gráficas de alta calidad en R. El paquete se basa en una gramática de gráficos que puede ser entendida a partir de entender sus componentes8: Data es aquél dataset que vamos a graficar, con toda la información pertinente para realizar el gráfico. geoms son representaciones para dibujar gráficos (puntos, líneas, cajas, entre otros). Stats son aquellas transformaciones estadísticas que le hagamos a los datos. Nos ayudan a hacer un resumen del dataset para visualizar mejor (por ejemplo, la media o la mediana son estadísticas de tendencia central). Scales nos ayudan a colorear (o escalar) la data según distintas variables. Dibujan los ejes y las leyendas. Coordinate Systems describe how geoms are mapped to the plane of the graphic. Facets nos permiten partir el dataset según factores para graficar en viñetas separadas. Themes son conjuntos de especificaciones gráficas que permiten controlar la apariencia general de todos los elementos que no son data (por ejemplo, el color del fondo o el ancho de los ejes). A lo largo de la explicación utilizaré el dataset iris, que contiene medidas de las ojas de tres especies de plantas: head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Veamos cómo se construye capa por capa un gráfico utilizando ggplot2 y los datos de iris. Para entender cómo funciona, es importante entender el argumento aes(), que permite indicar qué pondremos en los ejes XY y además permite . Veamos el ejemplo: library(ggplot2) ggplot(data=iris, aes(Sepal.Length, Petal.Length)) Este gráfico contiene los ejes que especificamos pero no contiene los datos. Para dibujarlos, debemos decirle a ggplot cómo hacerlo (por ejemplo, puntos). ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() Al parecer, los datos presentan una estructura de asociación entre el largo de los sépalos y el de los pétalos (a mayor largo de sépalos, mayor largo de pétalos). Este dataset contiene un factor Species con tres niveles, setosa, versicolor, virginica. Fácilmente podemos ver si las distintas especies presentan distintas asociaciones. Una forma rápida de visualizarlo es coloreando los puntos según el nivel del factor Species. En ggplot2 usamos color = Species. ggplot(iris, aes(Sepal.Length, Petal.Length, color = Species)) + geom_point() Podemos agregar una nueva capa con una línea de tendencia. Para hacerlo, especificamos un ajuste lineal (“lm”) en geom_smooth(method = &quot;lm&quot;). Es clave notar que geom_smooth() posee distintos métodos cuya riqueza exploraremos en los siguientes capítulos. ggplot(iris, aes(Sepal.Length, Petal.Length, color = Species)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Como pueden apreciar, incorporar la gramática de ggplot2 permite realizar visualizaciones más complejas con menor esfuerzo. La riqueza de este grupo de funciones esta en la gran variedad de funciones geom que podemos incorporar. A lo largo de el libro veremos varias de ellas. 4.2.1 Entendiendo aes() En ggplot, aes() hace referencia al contenido estético del gráfico (del ingles aesthetics). Es decir, la función le dará indicios a ggplot2 sobre cómo dibujar los distintos trazos, formas, colores y tamaños. Es importante notar que aes() crea una nueva capa en relación a las variables y agrega leyendas a los gráficos. Al incorporar aes() al llamado de ggplot() estamos compartiendo la información en todas las capas. Si deseamos que esa información sólo esté en una de las capas, debemos usar aes() en la capa correspondiente. Esto puede parecer confuso, las siguientes líneas de código generan un gráfico que se ve idéntico al que realizamos previamente: ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point(aes(color = Species)) # Notar diferencia! aes() aparece en geom_point() Sin embargo, podemos ver la diferencia al intentar repetir el gráfico con línea de tendencia. ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point(aes(color = Species))+ geom_smooth(method=&quot;lm&quot;) En este caso geom_smooth() no recibe la orden de agrupar segun Species, por ende, todos los datos son usados para construir el ajuste lineal. Este comportamiento nos permite gran versatilidad en los gráficos. Sin embargo, también permite que el usuario cometa algunos errores. Por ejemplo, intentemos cambiar todos los puntos del primer gráfico de negro a magenta: # Primer gráfico, izquierda ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point() # Intento 1 ggplot(iris, aes(Sepal.Length, Petal.Length, color=&#39;magenta&#39;)) + geom_point() # Intento 2 ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point(color=&#39;magenta&#39;) 4.2.2 Explorando geom Los distintas funciones geom nos permiten obtener resultados gráficos distintos, aunque utilicemos los mismos datos. Analicemos el largo de los sépalos por especie. # Gráfico de puntos p1 &lt;- ggplot(iris, aes(Species, Sepal.Length)) + geom_point() # Gráfico de puntos con ruido en el eje horizontal p2 &lt;- ggplot(iris, aes(Species, Sepal.Length)) + geom_jitter(width = 0.1) # Boxplot p3 &lt;- ggplot(iris, aes(Species, Sepal.Length)) + geom_boxplot() # Violin p4 &lt;- ggplot(iris, aes(Species, Sepal.Length)) + geom_violin() # Combinando boxplot y violin p5 &lt;- ggplot(iris, aes(Species, Sepal.Length)) + geom_violin(fill=&#39;orange&#39;, alpha=0.5)+ geom_boxplot(color=&quot;white&quot;, fill=&quot;black&quot;, lwd=0.8, width=0.2 ) # Grafico de barras con medias + SEM p6 &lt;- ggplot(iris, aes(Species, Sepal.Length)) + stat_summary(fun.y = mean, geom = &quot;bar&quot;, width=0.5) + stat_summary(fun.data = mean_se, geom = &quot;errorbar&quot;, color=&quot;red&quot;, width=0.5) Figure 4.1: Varias formas de mostrar los mismos datos. Este es un pequeño ejemplo de cómo los distintos geoms participan en la creación de gráficos. En A es difícil ver que los puntos están superpuestos, por eso en B usamos geom_jitter(), que da una buena idea de la distribución de los datos. Para resumir la información, es común utilizar gráficos de cajas o tipo violín (C,D). Notar que la combinación de geoms en capas permite fácilmente mezclar ambos gráficos (E). Al combinarlos, hemos cambiado cuestiones estéticas dentro de las capas para incrementar el contraste. Finalmente, otra forma común de hacer un resumen de datos es un gráfico de barras de tipo media ± SEM (E). 4.2.3 Explorando facet_wrap En otras secciones separamos datos categóricos utilizando color. En esta sección, veremos que es posible utilizar facets para separar las gráficas en distintas ventanas o viñetas. ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point()+ facet_wrap(~Species) Este comportamiento es súmamente útil cuando tenemos más de una variable categórica o cuando deseamos utilizar el color para simbolizar otra variable. Por ejemplo, quizás nos interesa evaluar cómo varía el ancho de los pétalos en las distintas plantas. ggplot(iris, aes(Sepal.Length, Petal.Length)) + geom_point(aes(color=Petal.Width))+ facet_wrap(~Species) En este último gráfico hemos podido representar con claridad variaciones en la longitud de pétalos y sépalos, el ancho de los pétalos y una variable categórica de tres niveles. Los datos indican que las plantas con menor longitud de pétalos y sépalos también poseen pétalos más angostos. Efectivamente, explotar los recursos de ggplot2 nos permite generar poderosas herramientas de análisis y comunicación estadística. 4.2.4 Cowplot Los gráficos realizados en la sección previa (4.2.2) muestran gráficos individuales que fueron acomodados distintos paneles. Para realizar esto, se ha utilizando el paquete cowplot. A continuación se muestra el código para realizar figura 4.1 # Si es la primera vez install.packages(&quot;cowplot&quot;) # Graficar en grilla cowplot::plot_grid(p1,p2,p3,p4,p5,p6, labels = &quot;AUTO&quot;) 4.3 Caso de estudio El primer objetivo de un análisis exploratorio debe ser ganar entendimiento cualitativo de la naturaleza de los datos (tendencia central, distribución y estructura de correlación). Esto puede lograrse utilizando tablas de resumen, sin embargo, en mi opinión el análisis gráfico es superior. En este caso voy a mostrar un análisis exploratorio del dataset de Titanic, que puede ser obtenido desde CRAN. # Si es la primera vez, install.packages(&#39;titanic&#39;) El dataset contiene información sobre el destino de los pasajeros del barco. Carguemos los paquetes necesarios para trabajar. # Paquete útil para reorganizar datos (parte de tidyverse) library(dplyr) # Cargamos el paquete titanic library(titanic) Vamos a trabajar con el dataset llamado titanic_train. En este caso es útil conocer a las variables que estaremos manejando. Puedes acceder al nombre de las variables con el comando names(titanic_train). Aquí hay una tabla con las descripciones de las variables. Variable Inglés Descr. Español Tipo de variable Valores survival Supervicencia dicotómica no, si (0, 1) pclass Clase factor 1, 2, 3 sex Sexo continua 0+ Age Edad en años continua 0+ sibsp # de hermanos o esposas a bordo continua 0+ parch # padres a bordo continua 0+ ticket Número de ticket caracter [A-Z][0-9] fare Valor del ticket continua 0+ cabin Número de cabina caracter [A-Z][0-9] embarked Puerto en donde embarcaron factor Cherbourg (C), Queenstown (Q), Southampton (S) Podemos utilizar la función str() para obtener una descripción rápida del tipo de datos que tenemos. Podemos ver que el dataset no necesariamente contiene las variables en las clases que queremos (por ejemplo, algunos factores están como character). str(titanic_train) ## &#39;data.frame&#39;: 891 obs. of 12 variables: ## $ PassengerId: int 1 2 3 4 5 6 7 8 9 10 ... ## $ Survived : int 0 1 1 1 0 0 0 0 1 1 ... ## $ Pclass : int 3 1 3 1 3 3 1 3 3 2 ... ## $ Name : chr &quot;Braund, Mr. Owen Harris&quot; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot; &quot;Heikkinen, Miss. Laina&quot; &quot;Futrelle, Mrs. Jacques Heath (Lily May Peel)&quot; ... ## $ Sex : chr &quot;male&quot; &quot;female&quot; &quot;female&quot; &quot;female&quot; ... ## $ Age : num 22 38 26 35 35 NA 54 2 27 14 ... ## $ SibSp : int 1 1 0 1 0 0 0 3 0 1 ... ## $ Parch : int 0 0 0 0 0 0 0 1 2 0 ... ## $ Ticket : chr &quot;A/5 21171&quot; &quot;PC 17599&quot; &quot;STON/O2. 3101282&quot; &quot;113803&quot; ... ## $ Fare : num 7.25 71.28 7.92 53.1 8.05 ... ## $ Cabin : chr &quot;&quot; &quot;C85&quot; &quot;&quot; &quot;C123&quot; ... ## $ Embarked : chr &quot;S&quot; &quot;C&quot; &quot;S&quot; &quot;S&quot; ... Cambiemos un par de cosas. # Transformamos en factor titanic_train$Survived &lt;- factor(titanic_train$Survived) # Transforamamos al castellano titanic_train$Sex &lt;- ifelse(titanic_train$Sex == &quot;male&quot;, &quot;hombre&quot;, &quot;mujer&quot;) # Transformamos una varibale con valor &quot;&quot; a NA titanic_train$Embarked &lt;- ifelse(titanic_train$Embarked == &quot;&quot;, NA, titanic_train$Embarked) Ahora sí, empecemos a entender el dataset gráficamente, una variable a la vez. Cada visualización responde a una pregunta respecto de la variable en cuestión. # Calculamos la supervivencia segun el factor Survived sobrev &lt;- titanic_train %&gt;% group_by(Survived) %&gt;% count() # Supervivencia # Cuál es el número de sobrevivientes? g1 &lt;- ggplot(titanic_train, aes(Survived)) + geom_bar()+ # Agregamos la cuenta de sobrevivientes # Notar que debemos utilizar otro data.frame en data # vamos a utilizar y=20 para posicionar los n cerca del eje x geom_text(data = sobrev, aes(Survived, y=25, label=n), color=&quot;white&quot;)+ xlab(&quot;Supervivencia&quot;)+ ylab(&quot;Frecuencia&quot;) # Clase # Cuál es la cantidad de pasajeros en cada clase? g2 &lt;- ggplot(titanic_train, aes(Pclass))+ geom_bar()+ xlab(&quot;Clase&quot;)+ ylab(&quot;Frecuencia&quot;) # Sexo # cuántos hombres y mujeres a bordo? g3 &lt;- ggplot(titanic_train, aes(Sex))+ geom_bar()+ xlab(&quot;Sexo&quot;)+ ylab(&quot;Frecuencia&quot;) # Lugar de embarque # dónde (en qué puerto) subió la gente al barco? g4 &lt;- ggplot(titanic_train, aes(Embarked))+ geom_bar()+ xlab(&quot;Lugar embarque&quot;)+ ylab(&quot;Frecuencia&quot;) # Edad de los pasajeros # Cuál es la distribución de edades de los pasajeros? g5 &lt;- ggplot(titanic_train, aes(Age))+ geom_histogram(binwidth = 5, color=&quot;white&quot;)+ xlab(&quot;Edad&quot;)+ ylab(&quot;Frecuencia&quot;) # Precio del ticket # Cuánto costaba subir al Titanic? g6 &lt;- ggplot(titanic_train, aes(Fare))+ geom_density(fill=&quot;gray50&quot;)+ xlab(&quot;Precio Ticket&quot;)+ ylab(&quot;Frecuencia&quot;) # Graficar todo junto! cowplot::plot_grid(g1,g2,g3,g4,g5,g6, labels=&quot;AUTO&quot;) Estos gráficos son bastante típicos. En esta sección concentro nuestros esfuerzos en entender el dataset rápidamente. Es posible hacer gráficos que comuniquen mejor. Más adelante retomaremos desde este punto (ver Sección 6.2). Ahora vamos a centrarnos en entender relaciones entre más de una variable. ggplot(titanic_train, aes(Sex, Survived))+ # Coloreamos segun la interaccion entre los niveles de interes geom_jitter(aes(color=interaction(factor(Sex), Survived)), alpha=0.5)+ # Separamos por clase facet_wrap(~Pclass)+ # Nombramos al eje ylab(&quot;Supervivencia&quot;)+ # Agregamos un eje y descriptivo scale_y_discrete(breaks=c(&quot;0&quot;,&quot;1&quot;), labels=c(&quot;No&quot;, &quot;Sí&quot;))+ # Sacamos la leyenda theme(legend.position = &quot;none&quot;)+ # mejoramos los colores scale_color_brewer(palette = &quot;Set2&quot;)+ # Titulo ggtitle(&quot;Supervivencia por clase&quot;) En el gráfico anterior podemos apreciar claramente que las mayor supervivencia se dio en las mujeres, y luego en las clases altas, siendo “hombre en tercera clase” la peor combinación. Ejercicio: Calcular % sobrevivientes # Calcular el porcentaje segun la clase titanic_train %&gt;% # Agrupar por clase y sexo # contar los sobrevivientes # sumar el total de casos # dividir por el total y expresar en porcentaje Podemos explorar cómo se relaciona la edad con la supervivencia. En el siguiente gráfico vemos que prácticamente no hay diferencias en supervivencia según las edades (quizás sí existen pequeñas diferencias para los niños menores de 10 años). ggplot(titanic_train, aes(Survived, Age, fill=Survived))+ geom_violin()+ geom_boxplot(fill=&quot;black&quot;, color=&quot;white&quot;, lwd=1.1, width=0.1)+ theme_bw()+ scale_fill_brewer(palette = &quot;Set2&quot;)+ theme(legend.position = &quot;none&quot;)+ xlab(&quot;Supervivencia&quot;)+ ylab(&quot;Edad (años)&quot;)+ scale_x_discrete(breaks=c(&quot;0&quot;,&quot;1&quot;), labels=c(&quot;No&quot;, &quot;Sí&quot;))+ # Rotamos los ejes! coord_flip() Ejercicio: Analizar sobrevivientes vs edad (por clase) # La base de este gráfico es la misma que la del anterior # Debemos cambiar el x a Pclass # (cuidado, necesitamos que Pclass sea un factor). Como queda el fill? ggplot(titanic_train, aes(x= ..., Age, fill=...))+ # Resto de los componentes? Veamos algunos componentes relacionados con el precio de los tickets. En general, podemos ver que, independientemente de la edad, el precio estaba por debajo de 50, con algunas notables excepciones en cero o por encima de 500 (A)!. También podemos ver que aquellos que pagaron más parecieran haber estado en el grupo de los sobrevivientes (B). # Edad vs Precio ticket p1 &lt;- ggplot(titanic_train, aes(Age, Fare)) + geom_point()+ xlab(&quot;Edad (años)&quot;)+ ylab(&quot;Precio ticket&quot;) p2 &lt;- ggplot(titanic_train, aes(Survived, Fare)) + geom_boxplot(aes(fill=Survived))+ xlab(&quot;Supervivencia&quot;)+ ylab(&quot;Precio ticket&quot;)+ scale_x_discrete(breaks=c(&quot;0&quot;,&quot;1&quot;), labels=c(&quot;No&quot;, &quot;Sí&quot;))+ theme(legend.position = &quot;none&quot;)+ scale_fill_brewer(palette = &quot;Set2&quot;) cowplot::plot_grid(p1,p2, labels=&quot;AUTO&quot;) 4.4 Resumen En este capítulo no he realizando una descripción exhaustiva sobre análisis gráfico, mi idea fue brindar ejemplos de las posibilidades para exploración de datos, principalmente con ggplot2. Uno de los mayores beneficios de R es la plataforma gráfica, principalmente ggplot2. ggplot2 está basada en una gramática que permite incorporar capas a los gráficos. Las capas son agregadas una encima de la otra segun los aes() y geoms que se utilicen. Tanto ggplot2 como paquetes accesorios permiten realizar gráficos de paneles de alta calidad. Utilizar combinaciones de capas permite representar con claridad más dimensiones en un gráfico. 4.5 Recursos El material sobre visualización de datos es virtualmente infinito. Recomiendo fuertemente los siguientes textos: ggplot2 online Data Visualization-Kieran Healy 4.6 Respuestas # Calculando el porcentaje de sobrevivientes por clase y sexo titanic_train %&gt;% group_by(Pclass, Sex) %&gt;% count(Survived) %&gt;% mutate(total=sum(n), porcentaje=n/total*100) ## # A tibble: 12 x 6 ## # Groups: Pclass, Sex [6] ## Pclass Sex Survived n total porcentaje ## &lt;int&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 hombre 0 77 122 63.1 ## 2 1 hombre 1 45 122 36.9 ## 3 1 mujer 0 3 94 3.19 ## 4 1 mujer 1 91 94 96.8 ## 5 2 hombre 0 91 108 84.3 ## 6 2 hombre 1 17 108 15.7 ## 7 2 mujer 0 6 76 7.89 ## 8 2 mujer 1 70 76 92.1 ## 9 3 hombre 0 300 347 86.5 ## 10 3 hombre 1 47 347 13.5 ## 11 3 mujer 0 72 144 50.0 ## 12 3 mujer 1 72 144 50.0 # La base de este gráfico es la misma que la del anterior # Debemos cambiar el x a Pclass # (cuidado, necesitamos que Pclass sea un factor). Como queda el fill? ggplot(titanic_train, aes(x= factor(Pclass), Age, fill=Survived))+ # Resto de los componentes? # (la principal es geom_violin(), el resto es estético) geom_violin() Estos fueron incluídos en inglés debido a que la función ggplot2 los utilizará en inglés y traducciones directas serían en perjuicio del usuario.↩ "],
["modelos-lineales.html", "Capítulo 5 Modelos Lineales 5.1 ¿Qué es un modelo lineal? 5.2 Modelos estadísticos 5.3 Esperanza 5.4 Estimación del modelo 5.5 Modelo en R 5.6 Supuestos 5.7 Análisis de supuestos en R 5.8 Visualizando residuos en R 5.9 Descomponiendo variabilidad 5.10 ¿Por qué hacer una regresión? 5.11 Resumen 5.12 Recursos 5.13 Respuestas Anexo", " Capítulo 5 Modelos Lineales Esencialmente, todos los modelos son erróneos, pero algunos son útiles - George Box La realidad es multidimensional, compleja e incierta. Un modelo es una representación formal de un fenómeno, una reducción de dimensionalidad que posee utilidad práctica. Dicha representación normalmente puede ser condensada en una expresión matemática, una fórmula, que indica cómo una variable se relaciona con otra(s). Empíricamente, el paradigma se basa en estudiar la relación matemática entre variables aleatorias respuesta, con una distribución de probabilidades dada, y aquellas variables que la predicen, con el fin de explicar asociaciones entre variables y realizar inferencia. De modo muy general, podemos escribir: \\[\\begin{equation} y = f(x) \\tag{5.1} \\end{equation}\\] Donde \\(y\\) es la variable que modelamos, \\(f\\) es una función de una o múltiples variable(s) explicatoria(s). 5.1 ¿Qué es un modelo lineal? En este capítulo trabajaremos con modelos lineales. Un modelo lineal suele escribirse como: \\[\\begin{equation} y = \\beta_0 + \\beta_1x_1 + \\ ...\\ + \\beta_nx_n \\tag{5.2} \\end{equation}\\] Donde \\(x_{1..n}\\) representa cada variable predictora y \\(\\beta_{1..n}\\) representan los coeficientes (o parámetros) a estimar. El efecto de cada coeficiente (por ejemplo, \\(\\beta_3\\)) debe interpretarse como el cambio en \\(y\\) dado por un cambio unitario en la variable predictora asociada a ese coeficiente (\\(x_3\\)), siempre que las demás variables \\(x\\) se mantengan constantes. Además, tenemos una ordenada al origen (o \\(\\beta_0\\)) que representa la media general. Este modelo es lineal porque está escrito como una combinación lineal de las preditoras y sus coeficientes. Por ejemplo, la ecuación de Michaelis-Menten9 es un modelo no lineal: \\[\\begin{equation} V_{prod} = V_{max} * \\frac{[S]}{K_m [S]} \\tag{5.3} \\end{equation}\\] Que podemos escribir en los términos usados en (5.2) como: \\[\\begin{equation} y = \\beta_0 *\\frac{x}{\\beta_1 x} \\end{equation}\\] 5.2 Modelos estadísticos Un modelo como el caracterizado por la ecuación ((5.2)) está determinado, es decir, dados los valores de \\(\\beta, x\\), los valores \\(y\\) son únicos. En nuestro caso trabajaremos con modelos estadísticos, en los que cada valor que medimos proviene de mediciones en la vida real y, por lo tanto, tiene asociado un error. \\[\\begin{equation} y_i = \\beta_0 + \\beta_1x_{1i} + \\ ...\\ + \\beta_nx_{ni} + \\epsilon_i \\tag{5.4} \\end{equation}\\] Donde \\(i\\) representa la observación obtenida de cada unidad experimental. Debido a que existen diferencias entre unidades experimentales, el valor de \\(y_i\\) no será determinado por una combinación lineal de \\(\\beta x\\), tendrá un error (\\(\\mathcal{E}_i\\)) asociado. 5.2.1 Simulando datos en R Podemos crear un ejemplo en R para visualizar rápidamente. Supongamos que podemos medir felicidad de manera cuantitativa, como una variable continua. Supongamos, además, que nuestro laboratorio quiere investigar cómo impactan distintas dosis de chocolate a la felicidad de los humanos. Para esto, tomamos una muestra de 100 voluntarios y los asignamos de manera aleatoria a 5 dosis de chocolate (20, 40, 60, 80, y 100 gramos). Los individuos consumen la dosis asignada, el chocolate aumenta su felicidad (según la fórmula \\(felicidad = dosis * 2.5 + 10\\)), que medimos y graficamos. # Paquetes que vamos a usar library(dplyr) library(ggplot2) # Permite cambiar el aspecto de ggplot a algo parecido a base library(ggthemes) # Generar participantes id &lt;- 1:100 # Generar dosis dosis &lt;- sort(rep(seq(20,100,20), 20)) # Generar respuesta &quot;ideal&quot; respuesta &lt;- dosis * 2.5 + 10 # Construir data.frame datos &lt;- data.frame(id=id, dosis=dosis, respuesta=respuesta) # Graficar p &lt;- ggplot(datos, aes(dosis, respuesta))+ geom_point()+ xlab(&quot;Dosis Chocolate (gr)&quot;)+ ylab(&quot;Felicidad&quot;)+ theme_base()+ theme(plot.background = element_rect(colour = NA)) p El modelo que construimos hasta ahora tiene valores determinados. Pero, en la realidad, esperamos variabilidad en la respuesta al chocolate entre individuos. Esta variabilidad existe porque los individuos no son réplicas exactas: cada cuerpo fue construido a partir de un genoma levemente distinto, con diferentes eventos en el desarrollo y la experiencia. Incluso podemos pensar en eventos aleatorios relacionados con la ingesta y digestión del mismo trozo de chocolate! Por eso, si queremos trabajar con un modelo más realista deberíamos tener un gráfico como el siguiente: # semilla set.seed(444) # Agregar ruido con distribucion normal (media 0, sd = 5) datos$respuesta &lt;- datos$respuesta + rnorm(n = 100, mean = 0, sd = 5) p &lt;- ggplot(datos, aes(dosis, respuesta))+ geom_point(alpha = 0.1)+ xlab(&quot;Dosis Chocolate (gr)&quot;)+ ylab(&quot;Felicidad&quot;)+ theme_base()+ theme(plot.background = element_rect(colour = NA)) p En este caso podemos ver claramente que para cada valor de dosis hemos registrado más de un valor de felicidad. La naturaleza de la pregunta cambia, debemos preguntarnos: ¿Cuál es el valor esperado de felicidad para una dada dosis de chocolate? ¿Cómo podemos estimarlo? 5.3 Esperanza Lo que esperamos en este caso es registrar valores que estén distribuidos alrededor del valor de la media para cada concentración (ver (5.4)). La esperanza va a estar dada por: \\[\\begin{equation} E(Y_i) = \\beta_0 + \\beta_1 x_{1i} \\tag{5.5} \\end{equation}\\] Donde \\(E(Y_i)\\) es la esperanza del caso \\(i\\) (también escrita como \\(\\mu_{Y|x_i}\\)), \\(\\beta_0\\) es el valor esperado para dosis cero (en este caso tiene sentido experimental pensar en participantes que no comieron chocolate), y \\(\\beta_1\\) es el incremento en la esperanza dado por un incremento unitario en la variable predictora (exactamente cuánto más feliz espero ser por gramo de chocolate!). Gráficamente, esperamos: # Graficar p + geom_smooth(method = &quot;lm&quot;, color=&quot;lightgray&quot;, se=FALSE)+ stat_summary(fun.y = mean, geom=&quot;point&quot;, size=2, color=&quot;red&quot;) 5.4 Estimación del modelo En este caso, los parámetros de nuestro modelo se estiman por cuadrados mínimos, una forma acotada de decir que buscaremos aquella recta (combinación lineal de parámetros y predictoras) tal que se minimice la suma de las distancias entre los datos y los valores predichos. Formalmente, podemos calcular el error o residuo, para cada punto como la diferencia entre el valor observado (\\(y_i\\)) y predicho por nuestro modelo (\\(E(Y_i)\\) o \\(\\hat{y_i}\\)): \\[\\begin{equation} e_i = y_i - E(Y_i) = y_i - \\hat{y_i} \\tag{5.6} \\end{equation}\\] Un inconveniente de esta definición es el signo de los residuos. Como no deseamos que los resultados varíen si las observaciones están por encima o por debajo de la esperanza, podemos usar el cuadrado de los residuos para trabajar. Usando la Ecuación (5.5) podemos expandir la Ecuación (5.6) y plantear: \\[\\begin{equation} \\Sigma e_i^2 = \\Sigma (y_i - E(Y_i))^2 = \\Sigma (y_i - (b_0 + b_1 x))^2 \\tag{5.7} \\end{equation}\\] Si minimizamos \\(\\Sigma e_i^2\\) podemos obtener estimadores para \\(\\beta_0\\) y \\(\\beta_1\\) (denotados como \\(b_0\\) y \\(b_1\\)): \\[\\begin{equation} b_1 = \\frac{\\Sigma (x_i - \\bar{x})(y_i - \\bar{y})}{\\Sigma (x_i - \\bar{x})^2} \\\\ b_0 = \\bar{y} - b_1 \\bar{x} \\tag{5.8} \\end{equation}\\] Donde \\(\\bar{x}\\) y \\(\\bar{y}\\) representan las respectivas medias en nuestra muestra. 5.4.1 Entendiendo la estimación con gráficos Si pensamos a los residuos como distancias entre nuestra recta de predichos y las observaciones de la vida real, lo que la regresión hace es minimizar esas distancias (todas a la vez, por eso en la Ecuación (5.7) tenemos la sumatoria). Supongamos que una primera aproximación a estimar el valor de \\(y\\) es olvidarse de la variación en \\(x\\) por un instante y plantear una recta que contenga a la media global (\\(\\bar{y}\\)) como valor esperado para cualquier \\(x\\) (equivalente a \\(y_i = \\beta_0 = \\bar{y}\\)): En este caso, vemos que los valores observados tienen una distancia grande a la media. Esto indica que \\(x\\) efectivamente tiene un efecto sobre \\(y\\). Sin embargo, cerca del centro (alrededor del punto \\((\\bar{x},\\bar{y})\\)), los residuos son pequeños. Intuitivamente, debemos cambiar la pendiente, pero, al rotar la recta, deberíamos hacerlo desde el punto \\((\\bar{x},\\bar{y})\\). Por ejemplo: Podemos ver que con esta acción hemos reducido los residuos y el ajuste es mejor. Naturalmente, es muy complicado encontrar gráficamente el par \\(b_0, b_1\\) tal que la suma de las distancias sean mínimas. En la siguiente figura se muestra la gráfica de dicha recta. Apenas se se pueden apreciar los residuos, pero podemos intuir que el ajuste es mucho mejor que nuestro primer intento con la media al observar las líneas punteadas. 5.5 Modelo en R Ya es hora de meternos de lleno en la práctica. Volvamos a nuestro modelo de felicidad y chocolate para realizar un ajuste lineal en R usando la función lm. Esta función requiere argumentos de tipo formula. En nuestro caso, queremos estudiar la relación entre la felicidad (respuesta) y la dosis de chocolate (dosis). Por ende, la fórmula que utilizaremos es respuesta ~ dosis, con ~ para dividir entre respuesta y predictoras:10 # crear modelo modelo_chocolate &lt;- lm(data=datos, respuesta ~ dosis) # Ver resultados del modelo summary(modelo_chocolate) ## ## Call: ## lm(formula = respuesta ~ dosis, data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.204 -3.696 -1.330 3.091 11.497 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.59279 1.15698 7.427 4.15e-11 *** ## dosis 2.51659 0.01744 144.283 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.933 on 98 degrees of freedom ## Multiple R-squared: 0.9953, Adjusted R-squared: 0.9953 ## F-statistic: 2.082e+04 on 1 and 98 DF, p-value: &lt; 2.2e-16 El llamado a summary() nos permite ver una gran cantidad de información. También recomiendo familiarizarse con el paquete broom, que nos permite extraer información estadística de los modelos. Aquí está la tabla con los estimadores: # Estimadores broom::tidy(modelo_chocolate) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 8.59 1.16 7.43 4.15e- 11 ## 2 dosis 2.52 0.0174 144 5.93e-116 A partir de la columna de estimadores (estimate), vemos que el consumo de chocolate incrementa la felicidad (esperamos mayor un incremento en ~2.5 unidades de felicidad por cada gramo de chocolate!). Nuestro modelo puede escribirse como: \\(felicidad = 2.52 * dosis + 8.59\\) En la tabla vemos que los estimadores tienen un error asociado, un estadístico t y su p-valor asociado. Por default, estos resultados están dados para un intervalo de confianza del 95%. Podemos ver que el cero no está incluido en el intervalo de nuestros estimadores. round(confint(modelo_chocolate), 3) ## 2.5 % 97.5 % ## (Intercept) 6.297 10.889 ## dosis 2.482 2.551 También podemos acceder a porciones del modelo por separado. Puedes intentar en tu consola los siguientes comandos. # parametros modelo_chocolate$coefficients # predichos modelo_chocolate$fitted.values # residuos modelo_chocolate$residuals Con nuestros estimadores, podríamos realizar inferencia (obtener predichos para dosis dentro del rango que no fueron testeadas). Pero, antes de avanzar, es necesario analizar el cumplimiento de los supuestos. 5.6 Supuestos Cuando construimos modelos de este tipo, asumimos ciertas cosas. Los supuestos principales en este caso son: Los valores de las predictoras no tienen error, son determinados por el investigador. Independencia entre observaciones. Homocedasticidad. Los residuos son normales. 5.6.1 Error en \\(x\\) La minimización de distancias se realiza únicamente sobre el componente \\(y\\). De esto se desprende el supuesto de que el componente \\(x\\) no tiene error asociado. Experimentalmente, esto es imposible (no es posible pesar exactamente 20.00 gr de chocolate). Sin embargo, en la gran mayoría de los casos, un error relativo pequeño en este componente, como por ejemplo el porcentaje de error de nuestra balanza, no afecta el análisis. 5.6.2 Independencia Los valores que obtenemos de cada unidad experimental deben ser independientes. Esto significa que los valores obtenidos de una unidad experimental no afectan los valores obtenidos por otra. Formalmente, \\(cov(y_i,y_j) = 0 \\ \\ \\forall \\ \\ i\\neq j\\). Una forma de facilitar independencia de observaciones es asignar los tratamientos (en este caso, la dosis de chocolate) al azar. 5.6.3 Homocedasticidad. Podemos pensar a cada uno de los valores que obtuvimos para una dosis como una subpoblación. En este modelo, la media de cada una de estas subpoblaciones está dada por la ecuación de esperanza (ver Ecuación (5.5)). Para cada subpoblación asumimos una distribución normal alrededor de \\(E(y_i)\\) con idéntica varianza (\\(\\sigma^2\\)). Formalmente: \\[\\begin{equation} \\sigma^{2}(Y_i|x_i) = \\sigma^{2}(Y_j|x_j) = \\sigma^2 \\ \\ \\forall \\ \\ i\\neq j \\tag{5.9} \\end{equation}\\] Este supuesto no es trivial y veremos cómo detectar su cumplimiento a partir del análisis de residuos (@(ref:normalidad-de-residuos)). Si este supuesto no se cumple, la pruebas de inferencia no es confiable, en especial si hay un grupo con varianza mucho más grande que el resto. Es posible corregir la heterocedasticidad con modelos más complejos que incluyan el modelado de varianza. 5.6.4 Normalidad de residuos Este modelo tiene como supuesto que los residuos se distribuyen de manera normal. En general, utilizaremos gráficos de diagnóstico, que son importantes para evaluar los supuestos. Residuos vs Predichos (Residuals vs Fitted) En este gráfico buscamos ver la dispersión respecto de la recta para cada valor predicho (cuánto se alejan de nuestro ajuste). Esperamos no observar ningún tipo de patrón en los residuos. Esperamos no ver datos atípicos (datos con residuos muy grandes). Q-Q Plot Este gráfico muestra cómo se acumulan los residuos respecto de los cuantiles teóricos de una distribución normal. Si la distribución de residuos es normal, los veremos cercanos a la recta. Desviaciones de la recta indican que la distribución de los residuos no es normal. Por ejemplo, en el siguiente gráfico muestro la comparación de residuos provenientes de una distribución Normal y una gamma en un Q-Q plot: Residuos estandarizados vs Predichos Este gráfico es similar al primero, pero los residuos están estandarizados. Esperamos no ver ningún patrón, con los residuos distribuidos normalmente alrededor de cero. En la siguiente figura muestro ejemplos de distintos gráficos de residuos vs predichos: En el primer caso veremos cómo son los gráficos deseados de residuos vs predichos. Tanto en A como en B tenemos residuos normales, la diferencia está en que para el modelo en B los predichos responden a niveles de un factor. Es importante mirar la dispersión de los residuos y que la variabilidad se mantenga constante a lo largo de todo el dominio. No hay reglas exactas para describir estos gráficos, se aprende mirando los patrones o, en este caso, la falta de ellos! En el segundo caso vemos problemas clásicos como los gráficos en forma de cono, predichos más altos tienen mayor variabilidad. Un gráfico de este estilo indica incumplimiento del supuesto de homocedasticidad. Finalmente, dos casos distintos. En D, vemos residuos con un patrón de \\(x^2\\), indica que nuestro modelo lineal no sigue el patrón de distribución de los datos. En E, vemos cómo modifica un outlier un gráfico al gráfico de residuos mostrado en A. Gráfico de puntos influyentes Los puntos influyentes son aquellos con gran palanca o leverage. Formalmente, dada la matriz de diseño de nuestro modelo \\(\\mathbf{X}\\) y la matriz de proyección \\(\\mathbf{H}=\\mathbf{X} \\ (\\mathbf{X}^{\\mathsf{T}}\\mathbf{X})^{-1} \\ \\mathbf {X} ^{\\mathsf{T}}\\), el leverage para la observación \\(i\\) está definido como el elemento \\(i\\) de la diagonal de la matriz \\(\\mathbf{H}\\) (\\(h_{ii}=\\mathbf{H}_{ii}\\)). Cuando tenemos pocas variables es fácil observarlos en el ajuste lineal. Vemos que aquellos puntos que están muy alejados en \\(x\\) tienen gran influencia sobre el ajuste. En particular, si estos puntos no se alinean bien con el patrón general de los datos, pueden forzar el modelo hacia un ajuste erróneo. Es conveniente tener buena cobertura, es decir, tomar registros igualmente espaciados a lo largo del rango de \\(x\\), para prevenir este tipo de eventos. En este caso, el punto en cuestión tiene alto residuo y alto leverage. La distancia de Cook (\\(D\\)) es una variable derivada de los residuos y el leverage, que permite determinar si una observación es influyente y se calcula a partir de la suma de los efectos en el modelo al eliminar cada observación. Valores de ditancia de Cook altos (\\(D_i &gt; 1\\)) indican que la observación es influyente. Un caso famoso es el cuarteto de Anscombe, cuatro datasets muy particulares que poseen prácticamente idéntica estadística descriptiva. Sin embargo, al graficarlos, vemos que son muy distintos11. # Crear los 4 graficos. p1 &lt;- my_plot(anscombe, x1, y1, dataset1) p2 &lt;- my_plot(anscombe, x2, y2, dataset2) p3 &lt;- my_plot(anscombe, x3, y3, dataset3) p4 &lt;- my_plot(anscombe, x4, y4, dataset4) # Ponerlos todos juntos con gridExtra gridExtra::grid.arrange(p1, p2, p3, p4) Figure 5.1: Cuarteto de Anscombe Un caso extremo fue desarrollado hace poco por Alberto Cairo y luego llevado a R en forma de paquete (datasauRus), cuya página puedes encontrar aquí. Abajo muestro un ejemplo básico de estos datasets. El mensaje que intento transmitir es: Siempre debemos inspeccionar gráficamente nuestro datos. library(datasauRus) ggplot(datasaurus_dozen, aes(x=x, y=y, colour=dataset))+ geom_point()+ theme_void()+ theme(legend.position = &quot;none&quot;)+ facet_wrap(~dataset, ncol=3) 5.7 Análisis de supuestos en R ¿Cómo podemos asegurarnos que nuestros modelos cumplen los supuestos? Podemos explorar el ajuste y analizar el cumplimiento de supuestos en R utilizando la función plot, que maneja bien objetos lm. Nuestro modelo fue armado teniendo en cuenta los supuestos, al analizar los gráficos de diagnóstico, vemos que se comporta de modo excelente. # Acomodamos las opciones gráficas para 4 gráficos en 2x2 par(mfrow = c(2, 2)) # graficamos el ajuste plot(modelo_chocolate) 5.7.1 Cuando los residuos no son normales En muchas ocasiones los gráficos de diagnóstico nos darán la idea de que no se cumplen los supuestos de normalidad de residuos (u homocedasticidad). En general, los modelos lineales son robustos a la ligera falta de normalidad. Existen distintas estratégias para manejar estos problemas que escapan los objetivos de este capítulo. 5.8 Visualizando residuos en R Nuestro modelo lineal asume que los errores están normalmente distribuidos alrededor de la esperanza. Formalmente, pedimos \\(\\mathcal{E}_i \\sim \\ \\mathcal{N}(\\mu,\\,\\sigma^{2})\\) donde \\(\\mu=0\\) y \\(\\sigma^{2} \\approx cte\\). En el modelo_chocolate este supuesto se cumple (lo armamos de ese modo12). En esta sección quiero explorar los residuos de los modelos lineales y brindar herramientas gráficas para conceptualizar mejor lo que la regresión está haciendo con nuestros datos. Voy a modificar los datos de chocolate para que el ajuste sea peor y permita visualizar los residuos mejor (básicamente agregamos ruido en dosis). # Agregar ruido en dosis creando nueva columna datos$nueva_dosis &lt;- datos$dosis + rnorm(100,10,10) # Calcular el nuevo modelo nuevo_modelo &lt;- lm(data = datos, respuesta~nueva_dosis) # Guardar los predichos del modelo en datos datos$nuevo_pred &lt;- nuevo_modelo$fitted.values # Guardar los residuos datos$residuos &lt;- nuevo_modelo$residuals # Veamos la data fit_plot &lt;- ggplot(datos, aes(nueva_dosis, respuesta))+ geom_smooth(method=&quot;lm&quot;, se=FALSE, color=&quot;lightgray&quot;)+ geom_point(alpha = 0.5) + theme_base()+ theme(plot.background = element_rect(colour = NA))+ xlab(&quot;Dosis Chocolate (gr)&quot;)+ ylab(&quot;Felicidad&quot;) fit_plot En este gráfico vemos que el ajuste sigue siendo bueno, pero hay mayor cantidad de puntos alejados de la recta. En vez de la recta de ajuste, usemos sólo los predichos. # Graficar pre_plot &lt;- ggplot(datos, aes(nueva_dosis, respuesta))+ geom_point()+ # Agregamos los predichos en una nueva capa! geom_point(aes(nueva_dosis, nuevo_pred), color=&quot;gray50&quot;, pch=1) + theme_base()+ theme(plot.background = element_rect(colour = NA))+ xlab(&quot;Dosis Chocolate (gr)&quot;)+ ylab(&quot;Felicidad&quot;) pre_plot Como vemos, los predichos están alineados perfectamente en la regresión. Podemos agregar los residuos de la siguiente forma: pre_plot + geom_segment(aes(xend = nueva_dosis, yend = nuevo_pred), alpha=0.5) Lo que nuestra regresión está realizando es minimizar la suma de los residuos al cuadrado (ver Ecuación (5.7)). Una herramienta para visualizar mejor los puntos con residuos grandes es graficarlos utilizando una escala de color y tamaño. ggplot(datos, aes(nueva_dosis, respuesta))+ #Agregamos opción de color dentro del geom_point() geom_point(aes(color = residuos, size=abs(residuos)))+ geom_point(aes(nueva_dosis, nuevo_pred), color=&quot;gray50&quot;, pch=1) + geom_segment(aes(xend = nueva_dosis, yend = nuevo_pred), alpha=0.5)+ theme_base()+ theme(plot.background = element_rect(colour = NA))+ xlab(&quot;Dosis Chocolate (gr)&quot;)+ ylab(&quot;Felicidad&quot;)+ # Agregamos color segun los residuos scale_color_gradientn(colours = c(&quot;red&quot;, &quot;black&quot;, &quot;red&quot;))+ # Sacamos la leyenda guides(color = FALSE, size = FALSE) 5.9 Descomponiendo variabilidad Existen distintas fuentes de variabilidad. La variabilidad total en nuestro modelo viene dada por la diferencia entre los datos observados y la media general (\\(y_i - \\bar{y}\\)). # Creamos un grafico base al que agregaremos varias capas grafico_base &lt;- ggplot(datos, aes(nueva_dosis, respuesta))+ geom_hline(yintercept = mean(datos$respuesta))+ geom_point() + theme_base(base_size = 12)+ theme(plot.background = element_rect(colour = NA))+ xlab(&quot;Dosis Chocolate (gr)&quot;)+ ylab(&quot;Felicidad&quot;)+ annotate(&quot;text&quot;, label = &quot;media global&quot;, x = 30, y = mean(datos$respuesta) + 15, size = 4, colour = &quot;black&quot;) # Variacion respecto de la media global variacion_total &lt;- grafico_base + geom_segment(aes(xend=nueva_dosis, yend=mean(datos$respuesta)), alpha=0.5)+ ggtitle(&quot;Variación total&quot;) # Graficar variacion_total Debido a que las predictoras tienen un efecto en los valores predichos, nuestro modelo logra efectivamente explicar una porción de la variabilidad total. Esta porción es la distancia entre la media y los valores predichos (\\(\\hat{y} - \\bar{y}\\)). # Variacion explicada variacion_explicada &lt;- grafico_base+ geom_smooth(method=&quot;lm&quot;, se=FALSE, color=&quot;lightgray&quot;)+ geom_point(aes(nueva_dosis, nuevo_pred), color=&quot;gray50&quot;, pch=1) + geom_segment(aes(xend = nueva_dosis, y = mean(datos$respuesta), yend = nuevo_pred), alpha=0.5)+ ggtitle(&quot;Variación explicada&quot;) #Graicar variacion_explicada Sin embargo, muchos puntos tienen un valor observado distinto al valor predicho (residuos ver Ecuación (5.6)). Decimos que es variación no explicada porque porque nuestro modelo predice distinto a lo observado, es decir, la variación en nuestras predictoras no puede explicar la diferencia observada. # Variacion no explicada por el modelo variacion_no_explicada &lt;- grafico_base + geom_smooth(method=&quot;lm&quot;, se=FALSE, color=&quot;lightgray&quot;)+ geom_point(aes(nueva_dosis, nuevo_pred), color=&quot;gray50&quot;, pch=1) + geom_segment(aes(xend = nueva_dosis, yend = nuevo_pred), alpha=0.5)+ ggtitle(&quot;Variación no explicada&quot;) # Graficar variacion_no_explicada Idealmente, queremos que la fracción de variabilidad explicada sea grande, cercana a la total. Esta información normalmente se condensa en el llamado coeficiente de determinación (\\(R^2\\)). Formalmente, podemos construir este coeficiente a partir de la suma de cuadrados explicada y total, aunque es más sencillo calcularlo a partir de su complemento: \\[\\begin{equation} R^2 = \\frac{SC_{exp}}{SC_{total}} = 1 - \\frac{\\Sigma(y_i - \\hat{y_i})^2}{\\Sigma (y_i - \\bar{y})^2} \\tag{5.10} \\end{equation}\\] \\(R^2\\) toma valores entre 0 y 1, con 1 como máximo valor predictivo. Una consecuencia de cómo está definido este coeficiente es que, al agregar variables a nuestros modelos, siempre incrementaremos el \\(R^2\\). Por eso es siempre conveniente utilizar el \\(R^2\\) ajustado según el número de predictoras. Afortunadamente, todos los softwares estadísticos ajustan el coeficiente automáticamente. # Podemos acceder al R^2 con summary(modelo_chocolate)$r.squared ## [1] 0.9953145 Ejercicio: calcular el modelo lineal para el cuarteto de anscombe con R^2 5.10 ¿Por qué hacer una regresión? Los objetivos de realizar un análisis de regresión pueden resumirse en: Describir la relación funcional entre X e Y (rectilínea, polinomial, cuadrática, …) Determinar cuánta de la variación en Y puede ser explicada por la variación de X y cuánto permanece sin explicar. Estimar los parámetros del modelo. Hacer inferencia sobre los parámetros del modelo (mediante pruebas de hipótesis y cálculo de intervalos de confianza). Predecir nuevos valores de Y para valores específicos de X en el dominio estudiado (interpolación dentro del rango de la(s) variable(s) predictora(s)). 5.11 Resumen Los modelos lineales se escriben como combinación lineal de estimadores y predictoras. Los modelos estadísticos tienen incorporado un error asociado con la variación entre las unidades experimentales. Cuando modelamos, modelamos la Esperanza dado una combinación de predictoras y un conjunto de supuestos sobre la distribución de nuestra variable respuesta. R posee herramientas analíticas y gráficas para escribir y evaluar el ajuste de modelos lineales. Una medida del valor predictivo de nuestro modelo es el coeficiente de determinación \\(R^2\\). 5.12 Recursos Un gran ejemplo para visualizar residuos aquí Una función que utiliza ggplot para crear gráficos de diagnóstico de modelos aquí 5.13 Respuestas Para calcular la regresión en el cuarteto de Anscombe podemos realizar lo siguiente. # Calcular los modelos m1 &lt;- lm(data = anscombe, y1~x1) m2 &lt;- lm(data = anscombe, y2~x2) m3 &lt;- lm(data = anscombe, y3~x3) m4 &lt;- lm(data = anscombe, y4~x4) # Ponerlos en una lista lista &lt;- list(m1=m1, m2=m2, m3=m3, m4=m4) Utilizando el paquete broom en conjunto con las funciones lapply y bind_rows podemos obtener resultados de todos los modelos juntos. Vemos que el ajuste de todos los modelos es idéntico (no debería sorprendernos si recordamos 5.1). # Obtener datos del ajuste bind_rows(lapply(lista, function(x) broom::tidy(x)), .id = &#39;modelo&#39;) ## # A tibble: 8 x 6 ## modelo term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 m1 (Intercept) 3.00 1.12 2.67 0.0257 ## 2 m1 x1 0.500 0.118 4.24 0.00217 ## 3 m2 (Intercept) 3.00 1.13 2.67 0.0258 ## 4 m2 x2 0.500 0.118 4.24 0.00218 ## 5 m3 (Intercept) 3.00 1.12 2.67 0.0256 ## 6 m3 x3 0.500 0.118 4.24 0.00218 ## 7 m4 (Intercept) 3.00 1.12 2.67 0.0256 ## 8 m4 x4 0.500 0.118 4.24 0.00216 Podemos obtener muchas medidas de ajuste con una estrategia similar (utilizando glance). En este caso, seleccionamos(con select) las columnas que contienen el \\(R^2\\). r_lista &lt;- lapply(lista, function(x) broom::glance(x)) # Obtener el R r_lista %&gt;% bind_rows(.id= &#39;modelo&#39;) %&gt;% select(modelo, r.squared, adj.r.squared) ## # A tibble: 4 x 3 ## modelo r.squared adj.r.squared ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 m1 0.667 0.629 ## 2 m2 0.666 0.629 ## 3 m3 0.666 0.629 ## 4 m4 0.667 0.630 Vemos que el \\(R^2\\) también es idéntico. Aprovecho para repetir el mensaje: Siempre es necesario graficar los datos! Anexo La función utilizada para realizar múltiples gráficos en 5.1 # Graficando con ggplot y gridExtra # Vamos a hacer 4 ggplots y ponerlos todos juntos con gridExtra # Esta función puede ser útil para acortar los llamados de cada gráfico my_plot &lt;- function(dataset, x_data, y_data, dataset_name){ x_data &lt;- enquo(x_data) y_data &lt;- enquo(y_data) dataset_name &lt;- enquo(dataset_name) plot1 &lt;- ggplot(dataset, aes(!!x_data, !!y_data), environment = environment())+ geom_point(color=&#39;black&#39;,size=3, alpha=0.8)+ theme_base()+ theme(plot.background = element_rect(colour = NA))+ scale_x_continuous(breaks = seq(0, 20, 2))+ scale_y_continuous(breaks = seq(0, 12, 2))+ geom_abline(intercept = 3, slope = 0.5, color = &quot;cornflowerblue&quot;)+ expand_limits(x = 0, y = 0) + labs(title = dataset_name) } Más información en la cinética enzimática aquí.↩ Si no puedes localizar la tilde en tu teclado, prueba ALT+126↩ La función utilizada para graficar fue construida con ggplot2 para ahorrar trabajo, para verla ir al Anexo al final del capítulo.↩ Cuando creamos el modelo, explícitamente definimos variación en \\(y\\) con la función rnorm(), con media 0 y sd constante. Para comprobar que el supuesto se cumple, puedes correr mean(modelo_chocolate$residuals) que dará como resultado un número muy pequeño, empíricamente cero. Además del qqplot, existen pruebas analíticas para normalidad: shapiro.test(datos$residuos) nos da un p&gt;0.05, que indica que no tenemos evidencias para decir que los residuos no siguen una distribución normal.↩ "],
["comunicacion.html", "Capítulo 6 Comunicación 6.1 Ciencia reproducible 6.2 Gráficos 6.3 RMarkdown 6.4 Texto 6.5 Separando líneas y párrafos 6.6 Trozos de código 6.7 Links e imágenes 6.8 Encabezado 6.9 Knit 6.10 Otros proyectos con RStudio 6.11 Notas 6.12 Recursos", " Capítulo 6 Comunicación El trabajo estadístico no termina cuando entendemos la estructura de los datos. Nuestro trabajo estará incompleto a menos que logremos llevar aquello que destilamos de la evidencia a la combinación correcta de palabras e imágenes que logren recrear el mensaje en otra mente. La mayoría de los usos a continuación son explotados a su máxima expresión si se posee cierta familiaridad con los sistemas de control de versiones (por ejemplo, GIT) y plataformas online basadas en dichos sistemas (por ejemplo, GitHub). Dicho material excede a la complejidad de este libro13. Sin embargo, los principios generales que desarrollo a continuación son independientes de los sistemas de control de versiones. 6.1 Ciencia reproducible Uno de los grandes motores detrás de la ciencia reproducible es el acceso a abierto a los datos y el código que se utilizó para analizarlos. La ventaja de realizar ciencia abierta de este modo es la disminución de errores de procedimiento que quedan escondidos en una computadora a la que nadie tiene acceso. Por ejemplo, un error de tipeo en una fórmula en Excel puede pasar desapercibido y llevar a conclusiones erróneas. Errores en planillas de Excel son muy complicados de hallar. Aunque parezca extremo, existen casos documentados de este tipo. Nota en Washington Post Nota en The Economist 6.2 Gráficos En un capítulo anterior realizamos análisis exploratorios. Como nuestro objetivo era entender los datos de manera rápida (ver Sección 4.3), dichos análisis no se focalizaron en comunicar visualmente hacia un externo o consumidor. Retomemos el dataset del Titanic y hagamos un gráfico tipo waffle (también conocidos como gráficos tipo tile o azulejo). # Si es la primera vez, vamos a necesitar unos cuantos paquetes # install.packages(&quot;rlang&quot;) # install.packages(&quot;stringi&quot;) # install.packages(&quot;curl&quot;) # install.packages(&quot;devtools&quot;) # devtools::install_github(&quot;hrbrmstr/waffle&quot;) # Paquete para hacer gráficos de tipo waffle library(waffle) library(tidyverse) library(titanic) # Calculamos supervivencia sobrev &lt;- titanic_train %&gt;% group_by(Survived) %&gt;% count() %&gt;% ungroup()%&gt;% mutate(Survived = c(&quot;No Sobrevivió&quot;, &quot;Sobrevivió&quot;)) # Waffle plot waffle(sobrev, rows = 25, size = 1, colors = c(&quot;#1696d2&quot;, &quot;#fdbf11&quot;), legend_pos = &quot;bottom&quot;)+ labs(title = &quot;Sobrevivientes del Titanic&quot;, subtitle = &quot;1 cuadrado = 1 persona&quot;) Este tipo de representaciones es común en los periódicos. Podemos recrear el gráfico por clase. # Calculamos supervivencia por clase sobrev2 &lt;- titanic_train %&gt;% group_by(Pclass, Survived) %&gt;% count() %&gt;% ungroup()%&gt;% mutate(Survived = ifelse(Survived==0,&quot;No Sobrevivió&quot;, &quot;Sobrevivió&quot;)) iron( waffle(filter(sobrev2, Pclass==1) %&gt;% select(-Pclass), rows = 10, size=1, colors = c(&quot;#1696d2&quot;, &quot;#fdbf11&quot;), legend_pos = &quot;none&quot;)+ labs(title = &quot;Sobrevivientes del Titanic por clase&quot;, subtitle = &quot;Primera clase&quot;), waffle(filter(sobrev2, Pclass==2) %&gt;% select(-Pclass), rows = 10, size=1, colors = c(&quot;#1696d2&quot;, &quot;#fdbf11&quot;), legend_pos = &quot;none&quot;)+ labs(subtitle = &quot;Segunda clase&quot;), waffle(filter(sobrev2, Pclass==3) %&gt;% select(-Pclass), rows = 10, size=1, colors = c(&quot;#1696d2&quot;, &quot;#fdbf11&quot;), xlab = &quot;1 cuadrado = 1 persona&quot;, legend_pos = &quot;bottom&quot;)+ labs(subtitle = &quot;Tercera clase&quot;) ) En la sección ?? observamos cómo podemos realizar un mapa con calidad de publicación. 6.3 RMarkdown Markdown es un lenguage de marcado ligero que permite agregar marcajes sencillos al texto plano (.md), para convertirlo en un poderoso conjunto de operaciones que pueden exportarse a formatos de publicación profesional como .html, .pdf y .tex14. RMarkdown es la implementación de Markdown dentro de Rstudio. RMarkdown posee toda la funcionalidad de Markdown y además permite introducir trozos de código. Los archivos de Rmarkdown son archivos de texto con extensión .Rmd. Podemos crearlos dentro de Rstudio desde el mismo menú con el que abrimos scripts. Abrir una ventana de Rmd Al abrirlo, un navegador nos permitirá seleccionar opciones (como el título, autor, etc). No me centraré en esa ventana debido a que todas estas opciones pueden modificarse en el encabezado del nuevo archivo .Rmd (ver Sección 6.8). 6.4 Texto Markdown es un lenguaje que permite escribir de manera veloz, con muy pocas distracciones. La funcionalidad para editar la presentación de texto es limitada, pero es más que suficiente para el 99% de las cosas que necesitamos al escribir. Los siguientes ejemplos están ordenados segun cómo se escriben en Rmarkdown y cómo es el render. Lo esencial es *invisible* a los ojos. \\(\\rightarrow\\) Lo esencial es invisible a los ojos. Lo esencial es **invisible** a los ojos. \\(\\rightarrow\\) Lo esencial es invisible a los ojos. Lo esencial es ~~in~~visible a los ojos. \\(\\rightarrow\\) Lo esencial es invisible a los ojos. Si tienes familiaridad con \\(\\LaTeX\\) es posible utilizarlo para fórmulas matemáticas en línea con la frase que se está escribiendo. Por ejemplo, un supuesto de los modelos lineales generales es \\(\\mathcal{E}_i \\sim \\ \\mathcal{N}(\\mu,\\,\\sigma^{2})\\). Utilzar \\(\\LaTeX\\) en RMarkdown es tan sencillo como englobar el código utilizando el símbolo $. Si queremos utilizar una ecuación, por ejemplo, utilizamos los entornos \\begin{equation} y \\end{equation} y escribimos sin necesidad de utilizar el símbolo $. Para utilizar resaltado tipo código en línea utilizamos palabras envueltas en backticks (`)15. Podemos utilizar código de R en la línea en la que estamos escribiendo de la forma r+espacio+función deseada. Por ejemplo, si combinamos con \\(\\LaTeX\\) y le preguntamos a R cuánto es \\(\\pi\\), nos dará el resultado en la misma línea así: \\(\\pi\\) = 3.141592716. 6.5 Separando líneas y párrafos La belleza de Rmarkdown es que acomoda el texto y las figuras automáticamente, por lo que no debemos preocuparnos por el número de líneas y demás problemas que aparecen con un editor de texto tradicional. Sin embargo, en ciertas ocasiones realmente deseamos forzar un quiebre, un espacio extra. Para separar párrafos, basta con terminar la línea que se está escribiendo con dos espacios. Por ejemplo, No te des por vencido, ni aún vencido, no te sientas esclavo, ni aún esclavo; Puede transformarse en: No te des por vencido, ni aún vencido, no te sientas esclavo, ni aún esclavo; Si agregamos dos espacios entre las palabras deseadas17. Las listas de objetos son un caso puntual muy útil: # Listas no numeradas * item 1 * item 2 + item 3 * item 4 * sub-item * sub-item Se ve así: item 1 item 2 item 3 item 4 sub-item sub-item # Listas numeradas 1. item 1 1. item 2 1. item 3 a) item 3a a) item 3b Se ve así: item 1 item 2 item 3 item 3a item 3b En las listas numeradas no debemos mantener la cuenta. Simplemente 1. y escribimos lo que necesitamos, Markdown hace el resto! Otra posibilidad es utilizar texto resaltado. Para resaltar texto utilizamos el símbolo mayor (&gt;) seguido de un espacio. Esta opción no es recomendada para uso extensivo, pero puede resaltar una frase corta de un modo interesante. Por ejemplo, R es genial. Cuando terminamos una sección o deseamos una marca física entre párrafos, podemos usar 3 asteriscos (*). # Línea horizontal *** Se ve: 6.6 Trozos de código En Rmarkdown podemos mezclar texto y código de R. La siguiente imagen muestra cómo se ve en mi computadora: El párrafo previo en mi editor Cuando estos trozos se agregan al documento final, corren en la consola de R y el output se incluye en los resultados. Por ejemplo, el siguiente trozo: summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 Para insertar trozos de código podemos hacer click en insert o mediante el comando rápido Ctrl+Alt+I. 6.7 Links e imágenes Los links e imágenes pueden incluirse utilizando corchetes ([]) y paréntesis. Por ejemplo, # Imágenes ![descripcion de mi imagen](link) # URLs [descripción de mi link](link) El link puede ser un directorio dentro de nuestra computadora (imagenes/vacaciones/.png) o via www con un link externo, como el logo de Rstudio: 6.8 Encabezado Los encabezados son útiles para diversos archivos, ciertamente necesarios para la organización de documentos más complejos. Rmarkdown utiliza un encabezado conocido como YAML y tiene la siguiente forma: --- title: &quot;Un mundo feliz&quot; author: &quot;Aldous Huxley&quot; date: &quot;1932&quot; output: html_document --- Por ejemplo, el encabezado de este libro es el siguiente18: --- title: &quot;Introducción a estadística con R&quot; author: &quot;Matias Andina&quot; date: &quot;2018-08-08&quot; site: bookdown::bookdown_site documentclass: book --- En este caso, la fecha la he creado con un llamado a la función Sys.Date() (r + espacio + Sys.Date()) que permite que cada vez que este libro se compila, se use la fecha de sistema para el compilado., De este modo, no tengo que actualizarlo manualmente cada vez que edito el libro. 6.9 Knit Para armar el documento, debemos hacer click en knit. El producto final será un documento tipo .html que contenga todo el texto y las imágenes del archivo .Rmd. 6.10 Otros proyectos con RStudio Presentaciones de diapositivas con Markdown y R presentation. Usando el paquete blogdown, Websites como este Usando el paquete bookdown, libros como éste (y otros!) 6.11 Notas Mucha tecnología cotidiana detrás de los servicios de publicación está principalmente desarrollada alrededor del idioma inglés. Problemas inesperados pueden aparecer incluso cuando hacemos todo bien utilizando R, Rstudio y Rmarkdown. Por ejemplo, mientras escribía este libro tuve un problema con el nombre de mis archivos que contenían tilde (por ejemplo, el archivo de este capítulo era “Comunicación.Rmd”). La inconveniente ó provocó que el link a ciertas imágenes del capítulo (www. .../Comunicación/imagen-01.png) no pudiera ser encontrado y dichas imágenes no aparecieran. La solición de compromiso es (como en muchas otras direcciones de internet) no utilizar caracteres que no existen en inglés (por ejemplo, la ñ, o palabras con tildes). 6.12 Recursos Cheatsheet oficial de Rmarkdown en español por Rstudio aquí Buen material sobre visualización con ggplot2 aquí Puedes aprender sobre GIT aquí↩ Puedes encontrar más información sobre Markdownaquí↩ Los backtics son difícilies de encontrar en el teclado en español, puedes probar ALT+96.↩ Para lograr esto el formato debe ser $\\pi$ = 3.1415927↩ Normalmente suelo agregar un enter y escribir en la siguiente línea. Aunque no es necesrario, me ayuda a visualizar el render antes de tiempo.↩ El encabezado que muestro es una porción que es comparable con un documento clásico. El encabezado real contiene ciertas especificaciones para que este libro pueda ser publicado online y entiendo que no aportan al ejemplo.↩ "],
["estadistica-espacial.html", "Capítulo 7 Estadística Espacial 7.1 Paquetes Geo-R 7.2 Paquetes GEO 7.3 Trabajando con datos espaciales 7.4 topological-relations 7.5 Nueva Zelanda 7.6 Proyecciones 7.7 Mapas animados 7.8 Mapas interactivos 7.9 Resumen 7.10 Recursos 7.11 Respuestas Anexo", " Capítulo 7 Estadística Espacial En este capítulo exploraremos herramientas estadísticas y de visualización para análisis de superficie. Nos centraremos en la capacidad gráfica de diversos paquetes de R. 7.1 Paquetes Geo-R Históricamente, el análisis de datos geográficos se centró en el paquete sp, que ha sido el más utilizado para manejar datos espaciales. La funcionalidad gráfica generalmente vino acoplada al mismo sp. El paquete sp guarda información espacial como vértices de polígonos, sistemas de coordenadas y otros atributos en objetos de la clase Spatial. Aunque la funcionalidad gráfica del paquete sp usando plot() es limitada, desarrollos recientes de paquetes como tmap, ggplot2, ggmap y leaflet permiten una amplia variedad de visualizaciones estáticas e interactivas, que pueden ser incorporadas a documentos .html como la versión electrónica de este libro. El paquete sf es un desarrollo relativamente reciente construido a partir de sp. 7.2 Paquetes GEO Vamos a instalar los paquetes que necesitamos para trabajar con data de tipo espacial. install.packages(&quot;sf&quot;) # tmap se toma su tiempo, instala muchas dependencias # usamos el repositorio de CRAN en vez del de Rstudio install.packages(&quot;tmap&quot;, repos = &quot;https://cloud.r-project.org&quot;) En Mac y Linux la instalación es más complicada, seguir instrucciones en: https://github.com/r-spatial/sf y en https://github.com/mtennekes/tmap Para facilitar que podamos trabajar con datasets abiertos, podemos cargar los datasets del paquete spData. install.packages(&quot;spData&quot;) Cargamos los paquetes que vamos a necesitar: library(ggplot2) library(dplyr) library(sf) library(tmap) library(spData) 7.3 Trabajando con datos espaciales Los datos geográficos pueden venir en base de vecotores localizados en un sistema de coordenadas de referencia. Un sitio puntual puede estar representado en longitud y latitud por un par coordenado (\\((x,y)\\)). Además, es posible encontrar datos que también posean información sobre altitud. Los puntos pueden conectarse formando polígonos (por ejemplo, los bordes de una región). Una pequeña demostración del dataset world de sf: plot(world) También podemos utilizar subsets del dataset world: plot(world[4:5]) Miremos el continente americano # subset americano &lt;- world %&gt;% filter(region_un==&quot;Americas&quot;) %&gt;% select(&quot;subregion&quot;, &quot;lifeExp&quot;) # Graficar plot(americano) El mismo resultado puede obtenerse usando base R (figura omitida). # Subset americano &lt;- world[world$region_un==&quot;Americas&quot;, c(&quot;subregion&quot;, &quot;lifeExp&quot;)] # Graficar plot(americano) Veamos con un poco más de profundidad cómo está organizado el dataset. Podemos ver que cada país tiene un código iso_a2 (dos letras que identifican a cada país)19, un nombre largo o name_long y un continente (podemos chequear toda la información en el dataset con names(world)). Vemos también que tenemos una columna geom con objetos MULTIPOLYGON de clase sfc_MULTIPOLYGON, `sfc. Estos geoms constituyen los bordes de los paises. world[1:5, 1:3] ## Simple feature collection with 5 features and 3 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -180 ymin: -18.28799 xmax: 180 ymax: 83.23324 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs ## iso_a2 name_long continent geom ## 1 FJ Fiji Oceania MULTIPOLYGON (((180 -16.067... ## 2 TZ Tanzania Africa MULTIPOLYGON (((33.90371 -0... ## 3 EH Western Sahara Africa MULTIPOLYGON (((-8.66559 27... ## 4 CA Canada North America MULTIPOLYGON (((-122.84 49,... ## 5 US United States North America MULTIPOLYGON (((-122.84 49,... 7.4 topological-relations 7.5 Nueva Zelanda En esta sección vamos a explorar el dataset nz como caso de estudio para demostrar la capacidad gráfica que adquirimos al trabajar en R con datos espaciales. # Fondo celeste par(bg = &#39;lightblue&#39;) # Si queremos hacer 2 gráficos # par(mfrow=c(1,2)) # Grafico de la isla plot(nz[1], col=&quot;gray80&quot;, main=&quot;Nueva Zelanda&quot;) plot(nz[2], main=&quot;Nueva Zelanda&quot;, key.pos = 1) La funcionalidad de base es limitada. Exploremos el paquete tmap que tiene una funcionalidad muy pareceida a ggplot2, con capas y gramática. # Mapa con bordes bordes &lt;- tm_shape(nz) + tm_borders() # Agregamos fill de un solo color con_color &lt;- bordes + tm_fill(col=&quot;red&quot;, alpha=0.3) # Agregamos fill segun el area de la region # Cuidado! no usamos aes(col= Land_area) cual ggplot2 area_region &lt;- tm_shape(nz) + tm_borders() + tm_fill(col = &quot;Land_area&quot;) # mostramos los mapas juntos tmap_arrange(bordes, con_color, area_region) Ejercicio: Investigar las opciones breaks y palette en tm_fill() 7.5.1 Cambiando colores con style El ejercicio anterior apunta a modificar a mano los valores de breaks. El paquete tm puede asignar los valores de corte de manera automática según un estilo o style (ver ?tm_polygons()): style = pretty (default), redondea a números enteros y los separa equidistantes. style = equal divide los valores de entrada en cortes de igual rango. Este tipo de estilo provoca que los mapas tengan poca variadad de color si tenemos una distribución asimétrica en la variable que elegimos para colorear. style = quantile divide en cuantiles nuestras observaciones de modo que el mismo número de observaciones entra en cada corte. style = jenks identifica grupos con valores similares y maximiza las diferencias entre grupos. style = cont nos proporciona un numero continuo de colores en un rango cromático. Podemos utilizarlo cuando queremos representar gradientes de terreno (gráficos tipo raster). style = cat nos sirve para representar variables categóricas de modo que cada categoría será coloreada con un color único. A continuación se muestran ejemplos de los distintos estilos: Podemos cambiar el estilo de manera global con: area_region + tm_style(&quot;classic&quot;) Podemos crear gráficos de calidad profesional. Ejercicio: Inspeccionar el siguiente código y comentar en cada línea su función. titulo_leyenda = expression(&quot;Area (km&quot;^2*&quot;)&quot;) tm_shape(nz) + tm_borders() + tm_fill(col = &quot;Land_area&quot;, title = titulo_leyenda) + tm_compass(type = &quot;4star&quot;, position = c(&quot;left&quot;, &quot;top&quot;)) + tm_scale_bar(breaks = c(0, 125, 250), size = 1, position = c(&quot;right&quot;, &quot;bottom&quot;))+ tm_layout(frame.lwd = 5, legend.outside = TRUE, legend.outside.position = c(&quot;right&quot;, &quot;bottom&quot;), legend.bg.color = NA, legend.format = list(text.separator = &quot;-&quot;)) 7.6 Proyecciones Para transformar el mundo de esfera a plano, utilizamos ciertas transformaciones matemáticas o proyecciones. A continuación muestro algunas proyecciones conocidas, utilizando datos de GDP per cápita20. Figure 7.1: GDP per cápita. Distintas proyecciones. Con pequeñas modificaciones al español. Fuente: https://github.com/mtennekes/tmap/tree/master/demo/WorldFacets La base para construir distintas proyecciones es cambiar el argumento projection en el comienzo del llamado. Para ver el código completo dirigirse al Anexo # longitud-latitud tm_shape(World, projection = &quot;longlat&quot;) + ... # robinson tm_shape(World, projection = &quot;robin&quot;) + ... # eck4 tm_shape(World, projection = &quot;eck4&quot;) + ... Podemos investigar otras transformaciones con ggplot2. Para hacerlo podemos utilizar la funcion st_transform() presente en sf. Podemos utilizar la siguiente transformación: “+proj=laea +y_0=0 +lon_0=40 +lat_0=10 +ellps=WGS84 +no_defs” # Transformar el objeto sf World world2 &lt;- sf::st_transform( World, &quot;+proj=laea +y_0=0 +lon_0=40 +lat_0=10 +ellps=WGS84 +no_defs&quot; ) # Graficar el nuevo objeto ggplot() + geom_sf(data = world2) + theme_bw() 7.7 Mapas animados 7.8 Mapas interactivos 7.9 Resumen 7.10 Recursos Este capítulo es un resumen del libro Geocomputation with R. Intenté resumir detalles técnicos que considero que son cruciales para usuarios avanzados pero que escapan a las intenciones de este libro introductorio. La viñeta de tmap aquí y aquí Más información sobre manejo de datos espaciales en R aquí Información sobre modificar la leyenda en tmap (http://www.jla-data.net/2017/09/20/2017-09-19-tmap-legend/) Información sobre proyecciones con ggplot2 (http://egallic.fr/maps-with-r/) 7.11 Respuestas Podemos cambiar la escala con la que se grafica utilizando breaks y podemos cambiar el tipo de colores utilizando el argumento palette. Por ejemplo: # Original area_region &lt;- tm_shape(nz) + tm_borders() + tm_fill(col = &quot;Land_area&quot;) # Modifico breaks para mayor detalle cortes &lt;- seq(0, 50000, 5000) area_2 &lt;- tm_shape(nz) + tm_borders() + tm_fill(col = &quot;Land_area&quot;, breaks = cortes) # modifico la paleta de colores # probar tmaptools::palette_explorer() area_3 &lt;- tm_shape(nz) + tm_borders() + tm_fill(col = &quot;Land_area&quot;, breaks = cortes, palette = &quot;viridis&quot;) # mostramos los mapas juntos tmap_arrange(area_region, area_2, area_3) Anexo La figura 7.1 fue construida con el siguiente codigo: data(&quot;World&quot;) longlat &lt;- tm_shape(World, projection = &quot;longlat&quot;) + tm_polygons(&quot;gdp_cap_est&quot;, palette = &quot;Purples&quot;, style = &quot;fixed&quot;, n = 7, breaks = c(0, 500, 2000, 5000, 10000, 25000, 50000, 1000000), title = c(&quot;GDP per cápita&quot;), legend.format = list(text.separator = &quot;-&quot;), textNA = &quot;Sin Datos&quot;) + tm_style(&quot;natural&quot;, earth.boundary = c(-180, -87, 180, 87)) + tm_format(&quot;World&quot;, inner.margins = 0.02, frame = FALSE) + tm_legend(position = c(&quot;left&quot;, &quot;bottom&quot;), bg.color = &quot;gray95&quot;, frame = TRUE)+ tm_credits(c(&quot;coordenadas longitud-latitud&quot;), position = c(&quot;RIGHT&quot;)) robin &lt;- tm_shape(World, projection = &quot;robin&quot;) + tm_polygons(&quot;gdp_cap_est&quot;, palette = &quot;Purples&quot;, style = &quot;fixed&quot;, n = 7, breaks = c(0, 500, 2000, 5000, 10000, 25000, 50000, 1000000), title = c(&quot;GDP per cápita&quot;), legend.format = list(text.separator = &quot;-&quot;), textNA = &quot;Sin Datos&quot;) + tm_style(&quot;natural&quot;, earth.boundary = c(-180, -87, 180, 87)) + tm_format(&quot;World&quot;, inner.margins = 0.02, frame = FALSE) + tm_legend(position = c(&quot;left&quot;, &quot;bottom&quot;), bg.color = &quot;gray95&quot;, frame = TRUE)+ tm_credits(c(&quot;Robinson (1963)&quot;), position = c(&quot;RIGHT&quot;)) eck4 &lt;- tm_shape(World, projection = &quot;eck4&quot;) + tm_polygons(&quot;gdp_cap_est&quot;, palette = &quot;Purples&quot;, style = &quot;fixed&quot;, n = 7, breaks = c(0, 500, 2000, 5000, 10000, 25000, 50000, 1000000), title = c(&quot;GDP per cápita&quot;), legend.format = list(text.separator = &quot;-&quot;), textNA = &quot;Sin Datos&quot;) + tm_style(&quot;natural&quot;, earth.boundary = c(-180, -87, 180, 87)) + tm_format(&quot;World&quot;, inner.margins = 0.02, frame = FALSE) + tm_legend(position = c(&quot;left&quot;, &quot;bottom&quot;), bg.color = &quot;gray95&quot;, frame = TRUE)+ tm_credits(c(&quot;Eckert IV (1906)&quot;), position = c(&quot;RIGHT&quot;)) # todo junto tmap_arrange(longlat, robin, eck4, nrow = 3) Trabajar con paises es particularmente complicado. Las mejores bases de datos poseen códigos internacionales de 2 o 3 letras pero es muy común encontrar problemas con los nombres cortos (o largos) de los distintos países. Además, los datos longitudinales agregan problemas cuando la composición geopolítica cambia (por ejmplo, es común encontrar datos en donde aún tenemos USSR como un país).↩ Para ver las distintas proyecciones disponibles recomiendo seguir el archivo de ayuda de la función de tmaptools que maneja proyecciones (?get_proj4). También Wikipedia↩ "],
["agradecimientos.html", "Agradecimientos", " Agradecimientos "]
]
